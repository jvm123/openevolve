{"id": "e9abc13d-338a-4920-a730-f010769fb437", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start, adaptive simulated annealing, and occasional large jumps.\n    \"\"\"\n    # Multi-start: sample several random starting points, keep best initial\n    n_starts = 5\n    best_x, best_y, best_value = None, None, np.inf\n    for _ in range(n_starts):\n        tx = np.random.uniform(bounds[0], bounds[1])\n        ty = np.random.uniform(bounds[0], bounds[1])\n        v = evaluate_function(tx, ty)\n        if v < best_value:\n            best_x, best_y, best_value = tx, ty, v\n\n    current_x, current_y, current_value = best_x, best_y, best_value\n    temperature = 2.0\n    cooling_rate = 0.985\n    min_temperature = 1e-3\n\n    no_improve_counter = 0\n    last_best_value = best_value\n\n    for i in range(iterations):\n        # Adaptive perturbation: mix local and global steps\n        if np.random.rand() < 0.85:\n            perturbation_scale = (0.15 + 0.3 * temperature) # local step\n        else:\n            perturbation_scale = np.random.uniform(0.5, 1.5) * (bounds[1] - bounds[0]) # large jump\n        \n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        # Stay in bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Accept according to SA\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / (temperature + 1e-10)) > np.random.rand()\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Track best\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Restart if stuck\n        if abs(last_best_value - best_value) < 1e-6:\n            no_improve_counter += 1\n        else:\n            no_improve_counter = 0\n        last_best_value = best_value\n\n        if no_improve_counter > 150:\n            # Do a global random restart with 20% chance\n            if np.random.rand() < 0.2:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n            no_improve_counter = 0\n\n        temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n", "language": "python", "parent_id": "ff2a1869-014d-4edc-9748-843d38f941eb", "generation": 6, "timestamp": 1747684656.84282, "metrics": {"runs_successfully": 1.0, "value": -1.5186637020546823, "distance": 1.7057965129438886, "value_score": 0.6307809903148338, "distance_score": 0.3695769416570083, "overall_score": 0.5}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 59 lines with 66 lines", "parent_metrics": {"runs_successfully": 1.0, "value": 0.25310585514464745, "distance": 4.0337738327377055, "value_score": 0.2987579670866074, "distance_score": 0.17765471232432553, "overall_score": 0.14651023878985242, "speed_score": 1.0, "reliability_score": 1.0, "combined_score": 0.3325511939492621, "success_rate": 1.0}}}