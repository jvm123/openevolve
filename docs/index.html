<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>OpenEvolve Evolution Visualizer</title>
    <script src="https://d3js.org/d3.v7.min.js"></script>
    <link rel="stylesheet" href="static/css/main.css">
</head>
<body>
    <div id="toolbar">
        <div style="display:flex;flex-direction:column;min-width:220px;">
            <span style="font-size:1.1em;font-weight:bold;">OpenEvolve Evolution Visualizer</span>
            <span id="checkpoint-label" style="font-size:0.9em;color:#888;">Checkpoint: None</span>
        </div>
        <div class="toolbar-spacer"></div>
        <div class="tabs">
            <div class="tab active" id="tab-branching">Branching</div>
            <div class="tab" id="tab-performance">Performance</div>
            <div class="tab" id="tab-list">List</div>
        </div>
        <label class="toolbar-label" for="metric-select">Metric:
        <select id="metric-select">
            <option value="combined_score" selected>combined_score</option>
        </select></label>
        <label class="toolbar-label" for="highlight-select">Highlight:
        <select id="highlight-select">
            <option value="none">None</option>
            <option value="top" selected>Top score</option>
            <option value="first">First generation</option>
            <option value="failed">Failed</option>
            <option value="unset">Metric unset</option>
        </select></label>
        <div class="toolbar-darkmode">
            <label class="toolbar-label" >Dark mode:</label>
            <input type="checkbox" id="darkmode-toggle">
            <span id="darkmode-label">ðŸŒ™</span>
        </div>
    </div>
    <div id="sidebar">
        <div id="sidebar-content">
            <span style="color:#888;">
                Select a node to see details.
            </span>
        </div>
    </div>
    <div id="view-branching" class="active" style="padding-top:3.5em;">
        <div id="graph"></div>
    </div>
    <div id="view-list" style="display:none;padding-top:3.5em;">
        <div style="display:flex;align-items:center;gap:1em;margin-bottom:1em;">
            <input id="list-search" type="text" placeholder="Search program ID..." style="font-size:1em;padding:0.4em 1em;border-radius:6px;border:1px solid #ccc;min-width:220px;">
            <select id="list-sort" style="font-size:1em;padding:0.3em 1em;border-radius:6px;border:1px solid #ccc;">
                <option value="id">Sort by ID</option>
                <option value="generation" selected>Sort by generation</option>
                <option value="island">Sort by island</option>
                <option value="score">Sort by score</option>
            </select>
        </div>
        <div id="node-list-container"></div>
    </div>
    <div id="view-performance" style="padding-top:4.5em;"></div>
    <div id="view-prompts" style="padding-top:3.5em;"></div>
    <script>window.STATIC_DATA = {"archive":["7e837bb2-f97e-47b8-98cd-82d28c4fe891","d819021f-e261-4988-80e6-fa7c521f68e1","e86a55b6-c88c-4f87-bea5-fa91b418d3e4","1576f604-4dd5-4b3f-88d8-29fff3a87f55","9d29a7d6-9ffb-4a30-b9f9-f3cb8497870d","ce21b5d0-3f22-435a-8b44-e20416b9d464","866f9429-d046-419c-9793-0c346ba212da","b25f9697-371b-440f-b54c-c7b33fee9955","ff2a1869-014d-4edc-9748-843d38f941eb","f533ce2b-cb5a-43ff-9fb0-2b7eafb531bd","8a86605a-8bc7-4c6c-a0a3-f4fdee4883bb","6377298e-87d3-4c58-9c11-982e017cd1b9","815b0c81-0ee6-46d2-ac1f-4197fb7c6c29","cbace538-30c1-4370-8ee7-46e2dd00371c","96538759-e6dd-4e66-9aaf-93c253650715","587b41ec-9e19-43ef-9756-ff4ecdfa1afd","c8d7f975-d28d-4d6d-9e7a-581a88a1ad10","dfb9bd3c-165a-4db2-aebc-b1f319a43e81","80394fea-7125-4276-bf69-be0f12c7234d","706d13f2-4663-46f6-93b6-78fcf043b2db"],"checkpoint_dir":"examples/function_minimization_oai/openevolve_output/checkpoints/checkpoint_100","edges":[{"source":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","target":"7e837bb2-f97e-47b8-98cd-82d28c4fe891"},{"source":"e0b5ce37-78b4-44cd-8fa2-72159efcf57c","target":"1ebc6456-165b-4e7b-996d-f9ee2fd87198"},{"source":"df745310-83ff-4a2f-b5c6-bb524df03055","target":"81d6976c-e7cc-4e18-826b-62dafdbc7d8e"},{"source":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","target":"55997bb5-e7a8-4a33-945e-fca9c2b8357c"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"e0b5ce37-78b4-44cd-8fa2-72159efcf57c"},{"source":"b25f9697-371b-440f-b54c-c7b33fee9955","target":"30a69acd-9fbf-4cd9-b0f6-e13d4f00b3c2"},{"source":"378c023c-827e-4016-b9de-265020c5e8dd","target":"d739b8c2-8dcc-41d6-bf83-eec8e490a417"},{"source":"5c6689f0-8227-4cd8-a461-c58cb10c9645","target":"e588e1f3-45a0-4ad5-a318-77a033c67ec1"},{"source":"96538759-e6dd-4e66-9aaf-93c253650715","target":"11bca1a2-44ae-4712-9043-07de95f59407"},{"source":"45e549b7-f72c-4e8d-8412-19a69435482e","target":"aaf989c7-9793-4899-86c1-59eaf2d6fd32"},{"source":"7e837bb2-f97e-47b8-98cd-82d28c4fe891","target":"7f0aaa32-7c2f-46e1-8ca3-2e9b4b359509"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01"},{"source":"e86a55b6-c88c-4f87-bea5-fa91b418d3e4","target":"873a0594-25e5-43fc-a5d7-168cc6bbbabe"},{"source":"8dc8fd18-8f8a-4737-b429-761dae9faae4","target":"c62eaa77-34e3-43ce-a2a2-811e5c450698"},{"source":"d5a8d81c-17fb-4052-97c3-34ed292ddbb1","target":"866f9429-d046-419c-9793-0c346ba212da"},{"source":"fbc34e4f-c22a-4e83-9d2b-3cbaa8ad7608","target":"057f5dc5-5e40-41f2-bf88-eeba9ce42de3"},{"source":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","target":"9a7a4b04-9d28-4c09-8304-fed12adf1bef"},{"source":"d819021f-e261-4988-80e6-fa7c521f68e1","target":"80394fea-7125-4276-bf69-be0f12c7234d"},{"source":"4d5f7a30-9954-49e8-9819-b2415aa9599a","target":"ed119f0e-967f-433b-be07-610dadb3b007"},{"source":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","target":"6377298e-87d3-4c58-9c11-982e017cd1b9"},{"source":"cbace538-30c1-4370-8ee7-46e2dd00371c","target":"4a8a354e-f7a4-4081-873b-9fa1f3474ddb"},{"source":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","target":"815b0c81-0ee6-46d2-ac1f-4197fb7c6c29"},{"source":"9d29a7d6-9ffb-4a30-b9f9-f3cb8497870d","target":"96538759-e6dd-4e66-9aaf-93c253650715"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"57f20e0e-88a3-4ba4-898f-ee581aac3168"},{"source":"f027dd64-4f56-41d8-bb01-4bb6c7065de7","target":"94d337dc-f6fa-4f96-8616-2dfa715d7441"},{"source":"8dc8fd18-8f8a-4737-b429-761dae9faae4","target":"1032f518-6add-4c3b-b848-5c4232439b35"},{"source":"7848162a-6e28-4748-994f-25407570d2b5","target":"2c47e181-1004-4279-9476-50f166783cce"},{"source":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","target":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"a9e78b1c-441a-4c8f-850c-829628b34b1c"},{"source":"7848162a-6e28-4748-994f-25407570d2b5","target":"d8e78925-dc67-44e3-8f33-ecc499720df5"},{"source":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","target":"706d13f2-4663-46f6-93b6-78fcf043b2db"},{"source":"97cdc700-2675-4141-87a5-dcf93f95bba0","target":"cac2b03c-4c1a-4848-bcfa-6f4e441f69dc"},{"source":"350e2a5b-a4bb-49eb-91ba-d8428603711d","target":"97cdc700-2675-4141-87a5-dcf93f95bba0"},{"source":"ce21b5d0-3f22-435a-8b44-e20416b9d464","target":"d819021f-e261-4988-80e6-fa7c521f68e1"},{"source":"378c023c-827e-4016-b9de-265020c5e8dd","target":"6bec508a-f78b-4291-9af6-4d6a37384980"},{"source":"378c023c-827e-4016-b9de-265020c5e8dd","target":"4f47720f-4f9d-43e1-b1f1-1eda6708c5e3"},{"source":"df745310-83ff-4a2f-b5c6-bb524df03055","target":"efccd91b-297f-4029-b9f9-effe9a3f538e"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"378c023c-827e-4016-b9de-265020c5e8dd"},{"source":"c8d7f975-d28d-4d6d-9e7a-581a88a1ad10","target":"eac7b8ae-c8cd-4104-925d-360521561854"},{"source":"c6fea3a7-8022-4565-9641-2f9496ccbd12","target":"15d74e04-bf8f-4e19-afc2-835e27ac00d7"},{"source":"2564795d-fa97-48bc-9235-9beda242ee38","target":"955314df-ad43-4b3b-a59c-f964427d379f"},{"source":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","target":"7848162a-6e28-4748-994f-25407570d2b5"},{"source":"8a86605a-8bc7-4c6c-a0a3-f4fdee4883bb","target":"c843ba2e-3257-4af0-8b9d-7efddbd7f187"},{"source":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","target":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"9d29a7d6-9ffb-4a30-b9f9-f3cb8497870d"},{"source":"ce21b5d0-3f22-435a-8b44-e20416b9d464","target":"15bbf12b-fd48-497e-8edc-2f6a878021db"},{"source":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","target":"81c191d8-75d4-4bb7-b287-f408e13afef2"},{"source":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","target":"fbc34e4f-c22a-4e83-9d2b-3cbaa8ad7608"},{"source":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","target":"cb0c3484-4358-4e0e-ace7-0f479fedf88f"},{"source":"706d13f2-4663-46f6-93b6-78fcf043b2db","target":"e9301cf9-0400-4cd3-ae96-5faa712febab"},{"source":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","target":"ce21b5d0-3f22-435a-8b44-e20416b9d464"},{"source":"706d13f2-4663-46f6-93b6-78fcf043b2db","target":"0092420a-cafb-4d70-b3f1-280521919b4e"},{"source":"706d13f2-4663-46f6-93b6-78fcf043b2db","target":"8e8dfb0a-60fd-4a10-a591-eb5cd6328e09"},{"source":"d819021f-e261-4988-80e6-fa7c521f68e1","target":"02877e86-5f0d-40dd-8f4f-355db54fe9ef"},{"source":"7e837bb2-f97e-47b8-98cd-82d28c4fe891","target":"641aba0c-77d2-4fb6-9046-59378e35da7e"},{"source":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","target":"8dc8fd18-8f8a-4737-b429-761dae9faae4"},{"source":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","target":"ff2a1869-014d-4edc-9748-843d38f941eb"},{"source":"6faffe31-1302-4428-b4dc-abfa216f23b3","target":"f027dd64-4f56-41d8-bb01-4bb6c7065de7"},{"source":"7e837bb2-f97e-47b8-98cd-82d28c4fe891","target":"078605d0-6f90-498d-878f-6de7a4ce0099"},{"source":"afac1ee8-bea7-496c-b102-c197942c8bfa","target":"f028dcf8-1187-4d9e-abbc-13af55ad1ac3"},{"source":"e86a55b6-c88c-4f87-bea5-fa91b418d3e4","target":"8a86605a-8bc7-4c6c-a0a3-f4fdee4883bb"},{"source":"ce21b5d0-3f22-435a-8b44-e20416b9d464","target":"600d84ab-ea0d-418b-8b02-4a00e6378024"},{"source":"d819021f-e261-4988-80e6-fa7c521f68e1","target":"20b0f31a-37ca-45f0-a870-ca164644f5d9"},{"source":"d819021f-e261-4988-80e6-fa7c521f68e1","target":"c8d7f975-d28d-4d6d-9e7a-581a88a1ad10"},{"source":"d819021f-e261-4988-80e6-fa7c521f68e1","target":"5c7f766a-c055-4cc1-8616-c19b894d2f74"},{"source":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","target":"4d5f7a30-9954-49e8-9819-b2415aa9599a"},{"source":"f533ce2b-cb5a-43ff-9fb0-2b7eafb531bd","target":"afac1ee8-bea7-496c-b102-c197942c8bfa"},{"source":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","target":"9de857f8-a6a5-4820-9c89-74ccd7d43890"},{"source":"1576f604-4dd5-4b3f-88d8-29fff3a87f55","target":"8715ee97-7152-488f-b085-9a0a7731120d"},{"source":"706d13f2-4663-46f6-93b6-78fcf043b2db","target":"eb97324d-0ef0-4464-9922-a74cb1211ce4"},{"source":"f533ce2b-cb5a-43ff-9fb0-2b7eafb531bd","target":"629c9627-552b-4876-b571-987c8c182a14"},{"source":"378c023c-827e-4016-b9de-265020c5e8dd","target":"e86a55b6-c88c-4f87-bea5-fa91b418d3e4"},{"source":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","target":"ff395f9d-67eb-4f2c-9fe3-9c20c126321a"},{"source":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","target":"5c6689f0-8227-4cd8-a461-c58cb10c9645"},{"source":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","target":"1576f604-4dd5-4b3f-88d8-29fff3a87f55"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"f57ef594-176b-495f-9c74-729279328664"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"45e549b7-f72c-4e8d-8412-19a69435482e"},{"source":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","target":"70276b82-e4ed-4d78-89f2-e76969f89438"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"e7cfc40d-11b2-4acb-aaac-2c7bd5401c51"},{"source":"45e549b7-f72c-4e8d-8412-19a69435482e","target":"df745310-83ff-4a2f-b5c6-bb524df03055"},{"source":"4d5f7a30-9954-49e8-9819-b2415aa9599a","target":"b9008af3-16d8-464c-b61b-e9d5815b1551"},{"source":"ff2a1869-014d-4edc-9748-843d38f941eb","target":"e9abc13d-338a-4920-a730-f010769fb437"},{"source":"97cdc700-2675-4141-87a5-dcf93f95bba0","target":"f3a276a9-ca5b-4aed-8ec2-0058e0d81205"},{"source":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","target":"2564795d-fa97-48bc-9235-9beda242ee38"},{"source":"815b0c81-0ee6-46d2-ac1f-4197fb7c6c29","target":"b25f9697-371b-440f-b54c-c7b33fee9955"},{"source":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","target":"a33b54f3-92e1-4539-8a59-a3b0ac75642f"},{"source":"6faffe31-1302-4428-b4dc-abfa216f23b3","target":"c6fea3a7-8022-4565-9641-2f9496ccbd12"},{"source":"57f20e0e-88a3-4ba4-898f-ee581aac3168","target":"f533ce2b-cb5a-43ff-9fb0-2b7eafb531bd"},{"source":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","target":"88698633-0f8c-4ad9-b03d-b801167e9efc"},{"source":"706d13f2-4663-46f6-93b6-78fcf043b2db","target":"9d127568-0ddb-4203-abc5-403471b6f568"},{"source":"4f47720f-4f9d-43e1-b1f1-1eda6708c5e3","target":"6faffe31-1302-4428-b4dc-abfa216f23b3"},{"source":"4f47720f-4f9d-43e1-b1f1-1eda6708c5e3","target":"cbace538-30c1-4370-8ee7-46e2dd00371c"},{"source":"fbc34e4f-c22a-4e83-9d2b-3cbaa8ad7608","target":"350e2a5b-a4bb-49eb-91ba-d8428603711d"},{"source":"815b0c81-0ee6-46d2-ac1f-4197fb7c6c29","target":"3e83b0cb-948b-47dd-918e-16079b60cd73"},{"source":"671651af-3148-47b4-ba64-5f6df7a748f7","target":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd"},{"source":"efccd91b-297f-4029-b9f9-effe9a3f538e","target":"4641484f-d863-43fb-93da-772e4dd52df3"},{"source":"b25f9697-371b-440f-b54c-c7b33fee9955","target":"e41f27e4-bebf-4000-bac4-a43d8a99f66b"},{"source":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","target":"d5a8d81c-17fb-4052-97c3-34ed292ddbb1"}],"nodes":[{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.999  # Slower cooling to allow for more exploration initially\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-6  # Even lower minimum temperature for finer search\n    stagnation_limit = 100  # More frequent checks for stagnation\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a more frequent restart mechanism if no improvement is found\n        if _ % stagnation_limit == 0 and current_value >= best_value:\n            # Random restart\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            cooling_rate *= 0.95  # Slightly decrease cooling rate to encourage exploration\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"7e837bb2-f97e-47b8-98cd-82d28c4fe891","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 5 lines with 5 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.05)' to 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1)'\nChange 3: Replace 14 lines with 8 lines","parent_metrics":{"combined_score":0.4486355733848136,"distance":0.8036624705482555,"distance_score":0.22602127933344787,"overall_score":0.16972711467696272,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.29619770166506365,"value_score":0.46804864930796547}},"metrics":{"combined_score":0.464591807419669,"distance":4.616838806467545,"distance_score":0.22352815010716592,"overall_score":0.1729183614839338,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8927860597767923,"value_score":0.4958889373125321},"parent_id":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","timestamp":1747683904.0091386},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995  # Slightly slower cooling for more exploration\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.05\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","island":0,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 5  # Number of random restarts' to 'n_starts = 10  # Increase number of random restarts'\nChange 2: Replace 2 lines with 2 lines\nChange 3: 'if it % 30 == 0:' to 'if it % 20 == 0:  # More frequent local search'","parent_metrics":{"distance":1.742211074526863,"distance_score":0.3646692296188536,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5168427467513017,"value_score":0.6300572913951241}},"metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014},"parent_id":"e0b5ce37-78b4-44cd-8fa2-72159efcf57c","timestamp":1747683413.0819752},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A robust global optimization algorithm combining multi-start, simulated annealing, and random restarts.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: run several independent simulated annealing searches\n    n_starts = 20  # Further increased for even better exploration\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n\n        temperature = 2.5  # Slightly higher starting temperature\n        cooling_rate = 0.98  # Slower cooling to maintain higher temperature longer\n        min_temperature = 1e-4\n\n        no_improve_count = 0\n        last_improve_iter = 0\n        max_no_improve = iterations // 8  # Trigger restart if stuck\n\n        for i in range(iterations):\n            # Generate a new candidate point by adding a scaled perturbation\n            perturbation_scale = max(0.3 * temperature, 0.03)  # Further refined for better balance\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n            # Ensure inside bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            if current_value < local_best_value:\n                local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n                no_improve_count = 0\n                last_improve_iter = i\n            else:\n                no_improve_count += 1\n\n            # Random restart if no improvement for several iterations\n            # Dynamic restart based on improvement rate\n            if no_improve_count > max_no_improve or (i - last_improve_iter) > iterations // (3 * n_starts):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Update best found across all starts\n        if local_best_value < best_value:\n            best_x, best_y, best_value = local_best_x, local_best_y, local_best_value\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"81d6976c-e7cc-4e18-826b-62dafdbc7d8e","island":0,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 10  # Increased for better exploration' to 'n_starts = 20  # Further increased for even better exploration'\nChange 2: 'for i in range(iterations // n_starts):' to 'for i in range(iterations):'\nChange 3: 'perturbation_scale = max(0.5 * temperature, 0.05)  # Adjusted minimum scale' to 'perturbation_scale = max(0.3 * temperature, 0.03)  # Further refined for better balance'\nChange 4: 'cooling_rate = 0.99  # Adjusted for smoother cooling' to 'cooling_rate = 0.98  # Slower cooling to maintain higher temperature longer'\nChange 5: 'if no_improve_count > max_no_improve or (i - last_improve_iter) > iterations // (2 * n_starts):' to 'if no_improve_count > max_no_improve or (i - last_improve_iter) > iterations // (3 * n_starts):'","parent_metrics":{"distance":1.7924826056410745,"distance_score":0.3581042897026133,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5007780014193184,"value_score":0.6237439362017807}},"metrics":{"distance":1.7090527885239075,"distance_score":0.369132710974183,"overall_score":0.5,"runs_successfully":1.0,"value":-1.518685102621792,"value_score":0.6307895053870993},"parent_id":"df745310-83ff-4a2f-b5c6-bb524df03055","timestamp":1747683837.36438},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.99  # Adaptive cooling rate for better balance\n        initial_temperature = temperature\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.5 * (temperature / initial_temperature), 0.01)  # Dynamic scale adjustment\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                from scipy.optimize import minimize\n                result = minimize(lambda v: evaluate_function(v[0], v[1]), [current_x, current_y], \n                                  method='Nelder-Mead', bounds=[bounds, bounds], options={'maxiter': 10})\n                if result.fun < current_value:\n                    current_x, current_y, current_value = result.x[0], result.x[1], result.fun\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"55997bb5-e7a8-4a33-945e-fca9c2b8357c","island":0,"language":"python","metadata":{"changes":"Change 1: Replace cooling_rate = 0.995  # Slightly slower cooling for more exploration with 2 lines\nChange 2: Replace 11 lines with 8 lines\nChange 3: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.5 * (temperature / initial_temperature), 0.01)  # Dynamic scale adjustment'","parent_metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014}},"metrics":{"error":0.0},"parent_id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","timestamp":1747684109.3618016},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 5  # Number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.994  # Slightly slower cooling for more exploration\n        min_temperature = 1e-4\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 30 == 0:\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.05\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"e0b5ce37-78b4-44cd-8fa2-72159efcf57c","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 52 lines with 74 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"distance":1.742211074526863,"distance_score":0.3646692296188536,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5168427467513017,"value_score":0.6300572913951241},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683351.4711306},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        if _ > 0 and _ % 100 == 0 and best_value >= current_value:\n            if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\n# Parallel exploration with multiple independent searches\ndef run_search(num_processes=5):\n    results = [search_algorithm() for _ in range(num_processes)]\n    # Return the best result found across all processes\n    return min(results, key=lambda res: res[2])\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"30a69acd-9fbf-4cd9-b0f6-e13d4f00b3c2","island":0,"language":"python","metadata":{"changes":"Change 1: Replace cooling_rate = 0.995  # Slightly slower cooling for more exploration with 4 lines\nChange 2: Replace perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01) with 3 lines\nChange 3: Replace 5 lines with 15 lines","parent_metrics":{"combined_score":0.4748157631584189,"distance":5.142933864815337,"distance_score":0.24393290238043105,"overall_score":0.4949631526316838,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9459474254643492,"value_score":0.5027264874071494}},"metrics":{"combined_score":0.4549984663511786,"distance":3.566537762643373,"distance_score":0.21898349296532385,"overall_score":0.17099969327023573,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.5953809887608323,"value_score":0.4821723641026358},"parent_id":"b25f9697-371b-440f-b54c-c7b33fee9955","timestamp":1747684694.853992},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.995\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-5  # Lower minimum temperature for finer search\n    stagnation_limit = 200  # Iterations before considering stagnation\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.1 * temperature, distance_to_best * 0.05)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Check for stagnation and adapt cooling rate\n        if _ % stagnation_limit == 0:\n            if current_value >= best_value:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                cooling_rate *= 0.9  # Decrease cooling rate to allow more exploration\n            else:\n                cooling_rate = initial_cooling_rate  # Reset cooling rate on improvement\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 4 lines\nChange 2: Replace perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature with 3 lines\nChange 3: Replace if _ % 100 == 0 and current_value >= best_value: with 9 lines","parent_metrics":{"combined_score":0.41411306444653023,"distance":2.4411503423243888,"distance_score":0.18678802902100744,"overall_score":0.16282261288930605,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8738212402463125,"value_score":0.43012775956704674}},"metrics":{"combined_score":0.4486355733848136,"distance":0.8036624705482555,"distance_score":0.22602127933344787,"overall_score":0.16972711467696272,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.29619770166506365,"value_score":0.46804864930796547},"parent_id":"378c023c-827e-4016-b9de-265020c5e8dd","timestamp":1747683640.83742},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing, local search, and evolutionary jumps.\n    Further improves exploration and robustness in escaping local minima.\n    \"\"\"\n    n_starts = 30  # Increase number of random restarts for broader exploration\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 2.0  # Slightly higher initial temperature for easier escape\n        cooling_rate = 0.993  # Slower cooling for more thorough exploration\n        min_temperature = 1e-10  # Lower minimum temperature for finer convergence\n\n        patience = 60  # Less patience before making a jump, encourages more exploration\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.8 * temperature, 0.02)  # Larger dynamic scale, min bound\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: more frequent and with momentum\n            if it % 7 == 0:\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.18 * (temperature / 2.0)  # Slightly larger adaptive step\n                momentum = 0.6\n                trial_x = np.clip(current_x - step * grad_x + momentum * np.random.normal(0, 0.01), bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y + momentum * np.random.normal(0, 0.01), bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # Evolutionary jump: occasionally mix in a global crossover\n            if it % 30 == 0 and start > 0 and best_x is not None:\n                # Crossover between current and best found\n                alpha = np.random.uniform(0.2, 0.8)\n                cross_x = alpha * current_x + (1 - alpha) * best_x\n                cross_y = alpha * current_y + (1 - alpha) * best_y\n                cross_x = np.clip(cross_x, bounds[0], bounds[1])\n                cross_y = np.clip(cross_y, bounds[0], bounds[1])\n                cross_value = evaluate_function(cross_x, cross_y)\n                if cross_value < current_value:\n                    current_x, current_y, current_value = cross_x, cross_y, cross_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                # Instead of random, jump near best found so far with noise\n                if best_x is not None and best_y is not None and np.isfinite(best_value):\n                    jump_x = best_x + np.random.normal(0, 1.3)\n                    jump_y = best_y + np.random.normal(0, 1.3)\n                    jump_x = np.clip(jump_x, bounds[0], bounds[1])\n                    jump_y = np.clip(jump_y, bounds[0], bounds[1])\n                    jump_value = evaluate_function(jump_x, jump_y)\n                    if jump_value < current_value:\n                        current_x, current_y, current_value = jump_x, jump_y, jump_value\n                    else:\n                        current_x = np.random.uniform(bounds[0], bounds[1])\n                        current_y = np.random.uniform(bounds[0], bounds[1])\n                        current_value = evaluate_function(current_x, current_y)\n                else:\n                    current_x = np.random.uniform(bounds[0], bounds[1])\n                    current_y = np.random.uniform(bounds[0], bounds[1])\n                    current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"e588e1f3-45a0-4ad5-a318-77a033c67ec1","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 74 lines with 104 lines","parent_metrics":{"distance":1.7520402516205702,"distance_score":0.3633667783060726,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5127957119492823,"value_score":0.6284548172158559}},"metrics":{"distance":1.686923787679366,"distance_score":0.372172818814365,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5152325589074755,"value_score":0.6294187394174849},"parent_id":"5c6689f0-8227-4cd8-a461-c58cb10c9645","timestamp":1747684512.2791836},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using Simulated Annealing with periodic random restarts and population-based exploration.\n    \"\"\"\n    # Parameters for population and exploration\n    population_size = 4\n    population = []\n    for _ in range(population_size):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        v = evaluate_function(x, y)\n        population.append({'x': x, 'y': y, 'v': v, 'cx': x, 'cy': y, 'cv': v, 't': 1.0})\n\n    cooling_rate = 0.997\n    min_temperature = 1e-4\n    restart_interval = iterations // 4\n    best_x, best_y, best_value = population[0]['x'], population[0]['y'], population[0]['v']\n\n    for it in range(iterations):\n        for ind in population:\n            # Adaptive perturbation: larger when temp is high or early in search\n            progress_factor = (it / iterations)\n            # Slightly increase scale for global jumps, but decrease as temp drops\n            perturbation_scale = max(0.35 * ind['t'] * (1 - progress_factor)**0.7, 0.015)\n            new_x = ind['x'] + np.random.uniform(-perturbation_scale, perturbation_scale)\n            new_y = ind['y'] + np.random.uniform(-perturbation_scale, perturbation_scale)\n            # Keep within bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_v = evaluate_function(new_x, new_y)\n            # Accept if better, or with probability if worse\n            if new_v < ind['v']:\n                accept = True\n            else:\n                accept = np.exp((ind['v'] - new_v) / ind['t']) > np.random.rand()\n            if accept:\n                ind['x'], ind['y'], ind['v'] = new_x, new_y, new_v\n            # Track personal best\n            if ind['v'] < ind['cv']:\n                ind['cx'], ind['cy'], ind['cv'] = ind['x'], ind['y'], ind['v']\n            # Global best\n            if ind['v'] < best_value:\n                best_x, best_y, best_value = ind['x'], ind['y'], ind['v']\n            # Anneal\n            ind['t'] = max(ind['t'] * cooling_rate, min_temperature)\n        # Occasional random restart for worst-performing particle\n        if (it+1) % restart_interval == 0:\n            worst = max(population, key=lambda d: d['cv'])\n            # Restart at a new random location or at global best + noise\n            if np.random.rand() < 0.5:\n                rx = np.random.uniform(bounds[0], bounds[1])\n                ry = np.random.uniform(bounds[0], bounds[1])\n            else:\n                rx = best_x + np.random.normal(0, 0.8)\n                ry = best_y + np.random.normal(0, 0.8)\n                rx = np.clip(rx, bounds[0], bounds[1])\n                ry = np.clip(ry, bounds[0], bounds[1])\n            rv = evaluate_function(rx, ry)\n            worst.update({'x': rx, 'y': ry, 'v': rv, 'cx': rx, 'cy': ry, 'cv': rv, 't': 1.0})\n        # Occasional cross-over: share info among population (like in DE or PSO)\n        if (it+1) % 75 == 0:\n            # Pick 2 random individuals and mix their coordinates\n            idx1, idx2 = np.random.choice(population_size, 2, replace=False)\n            ind1, ind2 = population[idx1], population[idx2]\n            # Arithmetic crossover\n            alpha = np.random.rand()\n            cross_x = alpha * ind1['x'] + (1 - alpha) * ind2['x']\n            cross_y = alpha * ind1['y'] + (1 - alpha) * ind2['y']\n            cross_x = np.clip(cross_x, bounds[0], bounds[1])\n            cross_y = np.clip(cross_y, bounds[0], bounds[1])\n            cross_v = evaluate_function(cross_x, cross_y)\n            # Replace worst of the two if new is better\n            if cross_v < max(ind1['v'], ind2['v']):\n                if ind1['v'] > ind2['v']:\n                    ind1['x'], ind1['y'], ind1['v'] = cross_x, cross_y, cross_v\n                else:\n                    ind2['x'], ind2['y'], ind2['v'] = cross_x, cross_y, cross_v\n                # Update personal bests\n                if cross_v < ind1['cv']:\n                    ind1['cx'], ind1['cy'], ind1['cv'] = cross_x, cross_y, cross_v\n                if cross_v < ind2['cv']:\n                    ind2['cx'], ind2['cy'], ind2['cv'] = cross_x, cross_y, cross_v\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"11bca1a2-44ae-4712-9043-07de95f59407","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 67 lines with 84 lines","parent_metrics":{"combined_score":0.42022379917416225,"distance":3.777583688551058,"distance_score":0.1715387091046857,"overall_score":0.16404475983483247,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8038628044982474,"value_score":0.44793697740459426}},"metrics":{"distance":1.6963299022872307,"distance_score":0.37087449838824416,"overall_score":0.5,"runs_successfully":1.0,"value":-1.518289241750869,"value_score":0.6306320334889788},"parent_id":"96538759-e6dd-4e66-9aaf-93c253650715","timestamp":1747684426.4385304},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A robust global optimization algorithm combining multi-start, simulated annealing, and random restarts.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: run several independent simulated annealing searches\n    n_starts = 5\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n\n        temperature = 2.0\n        cooling_rate = 0.98\n        min_temperature = 1e-4\n\n        no_improve_count = 0\n        last_improve_iter = 0\n        max_no_improve = iterations // 10  # Trigger restart if stuck\n\n        for i in range(iterations // n_starts):\n            # Generate a new candidate point by adding a scaled perturbation\n            perturbation_scale = max(0.5 * temperature * (1 + np.log1p(no_improve_count)), 0.01)\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n            # Ensure inside bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            if current_value < local_best_value:\n                local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n                no_improve_count = 0\n                last_improve_iter = i\n            else:\n                no_improve_count += 1\n\n            # Random restart if no improvement for several iterations\n            if no_improve_count > max_no_improve and (i - last_improve_iter) > iterations // 20:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Update best found across all starts\n        if local_best_value < best_value:\n            best_x, best_y, best_value = local_best_x, local_best_y, local_best_value\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"aaf989c7-9793-4899-86c1-59eaf2d6fd32","island":0,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.995' to 'cooling_rate = 0.98'\nChange 2: 'perturbation_scale = max(0.5 * temperature, 0.01)' to 'perturbation_scale = max(0.5 * temperature * (1 + np.log1p(no_improve_count)), 0.01)'\nChange 3: 'max_no_improve = iterations // 8  # Trigger restart if stuck' to 'max_no_improve = iterations // 10  # Trigger restart if stuck'\nChange 4: 'if no_improve_count > max_no_improve:' to 'if no_improve_count > max_no_improve and (i - last_improve_iter) > iterations // 20:'","parent_metrics":{"distance":1.7191620906425458,"distance_score":0.36776034920511014,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5034596772479558,"value_score":0.6247890076774529}},"metrics":{"distance":1.7130066125833203,"distance_score":0.3685947521697346,"overall_score":0.5,"runs_successfully":1.0,"value":-1.518496806588304,"value_score":0.6307145921593469},"parent_id":"45e549b7-f72c-4e8d-8412-19a69435482e","timestamp":1747683549.5170515},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x = np.random.uniform(bounds[0], bounds[1])\n    best_y = np.random.uniform(bounds[0], bounds[1])\n    best_value = evaluate_function(best_x, best_y)\n    \n    for _ in range(iterations):\n        # Simple random search\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        value = evaluate_function(x, y)\n        \n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":0,"id":"671651af-3148-47b4-ba64-5f6df7a748f7","island":0,"language":"python","metadata":{},"metrics":{"distance":1.7121946646425519,"distance_score":0.3687050981393303,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5124300045855732,"value_score":0.628310412285456},"parent_id":null,"timestamp":1747683294.3842876},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.995  # Adjust initial cooling rate for better exploration-exploitation balance\n    adaptive_cooling_rate = initial_cooling_rate\n    min_temperature = 1e-6  # Even lower minimum temperature for finer search\n    stagnation_limit = 100  # More frequent checks for stagnation\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.1 * temperature, distance_to_best * temperature)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a more frequent restart mechanism if no improvement is found\n        # Adaptive cooling rate adjustment based on iteration and improvement\n        if new_value < best_value:\n            adaptive_cooling_rate *= 0.995  # Encourage more exploitation when improving\n        else:\n            adaptive_cooling_rate *= 1.002  # Encourage exploration when stuck\n\n        # Implement a more diverse restart strategy\n        if _ % (stagnation_limit + np.random.randint(20)) == 0 and current_value >= best_value:\n            # Diverse random restart with consideration of historical best\n            current_x = best_x + np.random.uniform(-1, 1)\n            current_y = best_y + np.random.uniform(-1, 1)\n            current_value = evaluate_function(current_x, current_y)\n            adaptive_cooling_rate = initial_cooling_rate  # Reset cooling rate for new start\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"7f0aaa32-7c2f-46e1-8ca3-2e9b4b359509","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1)' to 'perturbation_scale = max(0.1 * temperature, distance_to_best * temperature)'\nChange 3: Replace 6 lines with 13 lines","parent_metrics":{"combined_score":0.464591807419669,"distance":4.616838806467545,"distance_score":0.22352815010716592,"overall_score":0.1729183614839338,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8927860597767923,"value_score":0.4958889373125321}},"metrics":{"error":0.0},"parent_id":"7e837bb2-f97e-47b8-98cd-82d28c4fe891","timestamp":1747684673.6506736},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        if _ > 0 and _ % 100 == 0 and best_value >= current_value:\n            if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 3 lines\nChange 2: Replace perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature with 2 lines\nChange 3: Replace 4 lines with 6 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"combined_score":0.3349001626270999,"distance":0.4841698181420444,"distance_score":0.1679899341660393,"overall_score":0.14698003252542,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.1066303074044817,"value_score":0.30750530396214687},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683338.643787},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start simulated annealing with random restarts.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: run several independent annealing chains and pick the best\n    n_starts = 5\n    chain_iters = iterations // n_starts\n    global_best_x, global_best_y, global_best_value = None, None, float('inf')\n    for start in range(n_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        best_x, best_y, best_value = current_x, current_y, current_value\n        temperature = 2.0  # Higher initial temperature\n        cooling_rate = 0.992  # Even slower cooling for more exploration\n        min_temperature = 1e-4\n\n        no_improve_count = 0\n        last_best_value = best_value\n\n        for i in range(chain_iters):\n            # Adaptive perturbation scale: larger at higher temperature, but never too small\n            perturbation_scale = max(0.3 * temperature, 0.02)\n            new_x = np.clip(current_x + np.random.normal(0, perturbation_scale), bounds[0], bounds[1])\n            new_y = np.clip(current_y + np.random.normal(0, perturbation_scale), bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            # Accept better or probabilistically worse\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update best found in this chain\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Adaptive random restart if stuck\n            if no_improve_count > 60 and temperature < 0.05:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n        \n        if best_value < global_best_value:\n            global_best_x, global_best_y, global_best_value = best_x, best_y, best_value\n\n    return global_best_x, global_best_y, global_best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"873a0594-25e5-43fc-a5d7-168cc6bbbabe","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 52 lines with 64 lines","parent_metrics":{"combined_score":0.4195085898276592,"distance":3.8937782311748976,"distance_score":0.21685621318163473,"overall_score":0.16390171796553188,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.1484761802416486,"value_score":0.4240862097886148}},"metrics":{"distance":1.7194022850017874,"distance_score":0.36772786634594695,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5184652353561823,"value_score":0.6307020333449735},"parent_id":"e86a55b6-c88c-4f87-bea5-fa91b418d3e4","timestamp":1747684481.8550062},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995 + 0.002 * (1 - it / iterations)  # Adaptive cooling\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.1  # Larger step for more aggressive local search\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"c62eaa77-34e3-43ce-a2a2-811e5c450698","island":0,"language":"python","metadata":{"changes":"Change 1: Replace cooling_rate = 0.995 + 0.002 * (1 - it / iterations)  # Adaptive cooling with 2 lines\nChange 2: Replace perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T with 2 lines\nChange 3: Replace step = 0.1  # Larger step for more aggressive local search with 2 lines\nChange 4: Replace 5 lines with 7 lines","parent_metrics":{"error":0.0}},"metrics":{"error":0.0},"parent_id":"8dc8fd18-8f8a-4737-b429-761dae9faae4","timestamp":1747683627.0249655},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slower initial cooling for better exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on temperature\n        perturbation_scale = 0.5 * temperature  # Larger initial exploration\n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        \n        # Ensure new_x and new_y remain within bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement an adaptive restart mechanism\n        # Trigger restart if no improvement in last 150 iterations\n        if _ > 0 and _ % 150 == 0 and best_value >= current_value:\n            if np.random.rand() > 0.5:\n                # Random restart\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n            else:\n                # Restart based on best found so far\n                current_x = best_x + np.random.normal(0, 0.1)\n                current_y = best_y + np.random.normal(0, 0.1)\n            current_value = evaluate_function(current_x, current_y)\n        \n        # Adaptive cooling based on progress\n        if new_value < best_value - 0.1:  # Significant improvement\n            cooling_rate = max(0.99, cooling_rate)  # Slow down cooling\n        temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Early stopping if solution converges\n        if temperature == min_temperature and abs(best_value - current_value) < 1e-6:\n            break\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"866f9429-d046-419c-9793-0c346ba212da","island":0,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.98  # Faster cooling to allow better convergence' to 'cooling_rate = 0.995  # Slower initial cooling for better exploration'\nChange 2: Replace 2 lines with 2 lines\nChange 3: Replace 7 lines with 12 lines\nChange 4: Replace temperature = max(temperature * cooling_rate, min_temperature) with 8 lines","parent_metrics":{"combined_score":0.3734818844387957,"distance":6.03703455848181,"distance_score":0.2282103926525655,"overall_score":0.15469637688775917,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6053483184137962,"value_score":0.3416979444050435}},"metrics":{"combined_score":0.4702429142855252,"distance":6.0561874862290415,"distance_score":0.19658514227827528,"overall_score":0.49404858285710507,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9280831613538908,"value_score":0.5187789526700711},"parent_id":"d5a8d81c-17fb-4052-97c3-34ed292ddbb1","timestamp":1747684623.4527283},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995  # Slightly slower cooling for more exploration\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.05\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"057f5dc5-5e40-41f2-bf88-eeba9ce42de3","island":0,"language":"python","metadata":{"changes":"Change 1: Replace perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T with 2 lines\nChange 2: Replace cooling_rate = 0.995  # Slightly slower cooling for more exploration with 2 lines\nChange 3: Replace 2 lines with 3 lines","parent_metrics":{"distance":1.6149312762401669,"distance_score":0.3824192280256911,"overall_score":0.5,"runs_successfully":1.0,"value":-1.4981511396923075,"value_score":0.6227236103704009}},"metrics":{"distance":1.6917650814427208,"distance_score":0.3715034446705967,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5175069045460774,"value_score":0.6303210539431203},"parent_id":"fbc34e4f-c22a-4e83-9d2b-3cbaa8ad7608","timestamp":1747683652.9850304},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.98  # Faster cooling to allow better convergence\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = 0.1 * temperature\n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        \n        # Ensure new_x and new_y remain within bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        # Trigger restart if no improvement in last 200 iterations\n        if _ > 0 and _ % 200 == 0 and best_value >= current_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"9a7a4b04-9d28-4c09-8304-fed12adf1bef","island":0,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.98  # Faster cooling to allow better convergence' to 'cooling_rate = 0.99  # Slower cooling to maintain higher temperature longer'\nChange 2: Replace 2 lines with 2 lines\nChange 3: 'perturbation_scale = 0.1 * temperature' to 'perturbation_scale = 0.1 * (temperature / 10)  # Scale perturbation based on relative temperature'\nChange 4: Replace 2 lines with 12 lines","parent_metrics":{"combined_score":0.35371181446008193,"distance":5.481650992896429,"distance_score":0.1794633008683563,"overall_score":0.15074236289201642,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8806981423956454,"value_score":0.33312137366595845}},"metrics":{"combined_score":0.3431696114932866,"distance":6.69049932218707,"distance_score":0.19783487321622836,"overall_score":0.14863392229865735,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.10208737955388059,"value_score":0.30636524921403024},"parent_id":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","timestamp":1747684745.7478921},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.995\n    min_temperature = 1e-6  # Lower minimum temperature for finer search\n    no_improvement_threshold = 100  # Introduce a threshold for restarting\n    last_best_value = best_value\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Improved random restart mechanism\n        if _ > 0 and _ % no_improvement_threshold == 0:\n            if best_value == last_best_value:  # Restart if no improvement\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n            last_best_value = best_value\n        \n        # Logarithmic cooling schedule\n        temperature = max(temperature / (1 + 0.01 * _), min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"80394fea-7125-4276-bf69-be0f12c7234d","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 4 lines with 5 lines\nChange 2: 'perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)' to 'perturbation_scale = max(0.1 * temperature, 0.01)  # Scale with temperature'\nChange 3: Replace 10 lines with 10 lines","parent_metrics":{"combined_score":0.47993143926861664,"distance":5.1890139004496065,"distance_score":0.2764172543253523,"overall_score":0.49598628785372334,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204993892200068,"value_score":0.4950104382850183}},"metrics":{"combined_score":0.4926334050351131,"distance":3.2048630836439553,"distance_score":0.23551198095124468,"overall_score":0.49852668100702263,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.5041582202992505,"value_score":0.536633017916233},"parent_id":"d819021f-e261-4988-80e6-fa7c521f68e1","timestamp":1747684575.3256521},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 12  # More random restarts for better global search\n    best_overall = None\n    best_value_overall = np.inf\n\n    for start in range(n_starts):\n        # Random initialization for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Annealing parameters for this run\n        temperature = 3.0  # Increase starting temperature for better exploration\n        cooling_rate = 0.995  # Even slower cooling to maintain exploration longer\n        local_iter = iterations // n_starts\n\n        for _ in range(local_iter):\n            # Adaptive step size based on temperature\n            step_size = 0.15 * temperature\n            # Propose a new candidate (clip to bounds)\n            new_x = np.clip(current_x + np.random.uniform(-step_size, step_size), bounds[0], bounds[1])\n            new_y = np.clip(current_y + np.random.uniform(-step_size, step_size), bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                delta = new_value - current_value\n                accept = np.exp(-delta / max(temperature, 1e-8)) > np.random.rand()\n\n            # Accept or reject\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best for this run\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Cool down\n            temperature *= cooling_rate\n\n        # After annealing, perform a brief local search (hill climbing)\n        momentum = np.array([0.0, 0.0])\n        alpha = 0.8  # Momentum factor\n        for i in range(15):\n            grad_x = (evaluate_function(best_x + 1e-4, best_y) - evaluate_function(best_x - 1e-4, best_y)) / 2e-4\n            grad_y = (evaluate_function(best_x, best_y + 1e-4) - evaluate_function(best_x, best_y - 1e-4)) / 2e-4\n            # Adaptive step size\n            step = 0.05 / (1 + 0.1 * i)\n            momentum = alpha * momentum - step * np.array([grad_x, grad_y])\n            best_x = np.clip(best_x + momentum[0], bounds[0], bounds[1])\n            best_y = np.clip(best_y + momentum[1], bounds[0], bounds[1])\n            best_value = evaluate_function(best_x, best_y)\n\n        # Track the best overall result\n        if best_value < best_value_overall:\n            best_overall = (best_x, best_y, best_value)\n            best_value_overall = best_value\n\n    return best_overall\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"ed119f0e-967f-433b-be07-610dadb3b007","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: Replace 8 lines with 11 lines","parent_metrics":{"distance":1.6447942907207354,"distance_score":0.3781012396724015,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5065319973050537,"value_score":0.6259906291161944}},"metrics":{"distance":1.633414347326884,"distance_score":0.37973515296408866,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5094233905848353,"value_score":0.6271257173192608},"parent_id":"4d5f7a30-9954-49e8-9819-b2415aa9599a","timestamp":1747683665.91339},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.98\n    cooling_rate = initial_cooling_rate\n    improvement_factor = 0.95  # Factor to reduce cooling rate if no improvement\n    min_temperature = 1e-5  # Lower minimum temperature for finer search\n    stagnation_limit = 200  # Iterations before considering stagnation\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.2 * temperature, (iterations - _) / iterations)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Check for stagnation and adapt cooling rate\n        if _ % stagnation_limit == 0:\n            if current_value >= best_value:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                cooling_rate *= improvement_factor  # Decrease cooling rate to allow more exploration\n            else:\n                cooling_rate = initial_cooling_rate  # Reset cooling rate on improvement\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"6377298e-87d3-4c58-9c11-982e017cd1b9","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 3 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.05)' to 'perturbation_scale = max(0.2 * temperature, (iterations - _) / iterations)'\nChange 3: 'cooling_rate *= 0.9  # Decrease cooling rate to allow more exploration' to 'cooling_rate *= improvement_factor  # Decrease cooling rate to allow more exploration'","parent_metrics":{"combined_score":0.4486355733848136,"distance":0.8036624705482555,"distance_score":0.22602127933344787,"overall_score":0.16972711467696272,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.29619770166506365,"value_score":0.46804864930796547}},"metrics":{"combined_score":0.5505239260445507,"distance":2.8944020275163918,"distance_score":0.30363374633029705,"overall_score":0.5101047852089102,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.5305748189281594,"value_score":0.5990563369091026},"parent_id":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","prompts":{"prompt_0":"You are an expert in evolutionary algorithms. Your task is to improve the search algorithm for a complex function minimization problem. The current implementation uses a basic simulated annealing approach. Your goal is to enhance the algorithm's performance by making it more efficient and robust against local minima. Consider introducing dynamic perturbation scales, adaptive cooling rates, and mechanisms to escape local minima effectively.","prompt_1":"The current search algorithm is designed to minimize a complex function. It uses simulated annealing with a fixed perturbation scale and cooling rate. Your task is to improve this algorithm by making it more adaptive to the search space. Consider implementing dynamic perturbation scales based on the distance from the best known point, adaptive cooling rates that respond to the search progress, and mechanisms to escape local minima effectively.","prompt_2":"The current search algorithm is designed to minimize a complex function. It uses simulated annealing with a fixed perturbation scale and cooling rate. Your task is to improve this algorithm by making it more adaptive to the search space. Consider implementing dynamic perturbation scales based on the distance from the best known point, adaptive cooling rates that respond to the search progress, and mechanisms to escape local minima effectively."},"timestamp":1747683930.056656},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global minimization using Simulated Annealing + Differential Evolution restarts.\n    \"\"\"\n    def evaluate_population(pop):\n        return np.array([evaluate_function(x, y) for x, y in pop])\n\n    # Differential Evolution parameters\n    pop_size = 8\n    F = 0.8\n    CR = 0.9\n\n    # Simulated Annealing parameters\n    temperature = 2.0\n    cooling_rate = 0.995\n    min_temperature = 1e-4\n    no_improvement_threshold = 150\n    last_improvement_iter = 0\n\n    # Random initialization for population\n    pop = np.random.uniform(bounds[0], bounds[1], size=(pop_size, 2))\n    pop_vals = evaluate_population(pop)\n    best_idx = np.argmin(pop_vals)\n    best_x, best_y, best_value = pop[best_idx][0], pop[best_idx][1], pop_vals[best_idx]\n\n    current_x, current_y = best_x, best_y\n    current_value = best_value\n\n    for i in range(iterations):\n        # Simulated Annealing step\n        perturb = max(0.2 * temperature, 0.02)\n        new_x = current_x + np.random.uniform(-perturb, perturb)\n        new_y = current_y + np.random.uniform(-perturb, perturb)\n        # Clamp to bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        accept = False\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / (temperature+1e-8)) > np.random.rand()\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update best\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n            last_improvement_iter = i\n\n        # Differential Evolution restart if stagnation\n        if i - last_improvement_iter > no_improvement_threshold:\n            # DE step: evolve population for a few generations\n            for _ in range(7):  # a few generations\n                for j in range(pop_size):\n                    idxs = [idx for idx in range(pop_size) if idx != j]\n                    a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n                    mutant = np.clip(a + F*(b-c), bounds[0], bounds[1])\n                    cross = np.random.rand(2) < CR\n                    trial = np.where(cross, mutant, pop[j])\n                    trial_val = evaluate_function(trial[0], trial[1])\n                    if trial_val < pop_vals[j]:\n                        pop[j] = trial\n                        pop_vals[j] = trial_val\n            # Reset current solution to best in population\n            best_idx = np.argmin(pop_vals)\n            current_x, current_y = pop[best_idx][0], pop[best_idx][1]\n            current_value = pop_vals[best_idx]\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n            last_improvement_iter = i\n            # Also mix in a new random solution to maintain diversity\n            pop[np.argmax(pop_vals)] = np.random.uniform(bounds[0], bounds[1], 2)\n            pop_vals[np.argmax(pop_vals)] = evaluate_function(pop[np.argmax(pop_vals)][0], pop[np.argmax(pop_vals)][1])\n\n        temperature = max(temperature * cooling_rate, min_temperature)\n\n    return float(best_x), float(best_y), float(best_value)\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"4a8a354e-f7a4-4081-873b-9fa1f3474ddb","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 71 lines with 78 lines","parent_metrics":{"combined_score":0.5020846298652628,"distance":2.8298516401660767,"distance_score":0.2559468909629838,"overall_score":0.5004169259730527,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1505276454007851,"value_score":0.5421676042939461}},"metrics":{"distance":1.7146746767736392,"distance_score":0.3683682647338387,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5184679820375322,"value_score":0.6307031259356578},"parent_id":"cbace538-30c1-4370-8ee7-46e2dd00371c","timestamp":1747684801.602202},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        if _ > 0 and _ % 100 == 0 and best_value >= current_value:\n            if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"815b0c81-0ee6-46d2-ac1f-4197fb7c6c29","island":0,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)' to 'perturbation_scale = max(0.1 * temperature * (1 + 0.5 * np.random.rand()), 0.01)'\nChange 2: 'cooling_rate = 0.995  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.99 + 0.005 * (1 - _ / iterations)  # Dynamic cooling rate'\nChange 3: Replace 5 lines with 5 lines","parent_metrics":{"combined_score":0.3349001626270999,"distance":0.4841698181420444,"distance_score":0.1679899341660393,"overall_score":0.14698003252542,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.1066303074044817,"value_score":0.30750530396214687}},"metrics":{"combined_score":0.33160088894832396,"distance":4.643351228821235,"distance_score":0.1684000789977336,"overall_score":0.14632017778966483,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9004838666565715,"value_score":0.30180144208167314},"parent_id":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","timestamp":1747683491.7186558},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.998  # Slow down cooling to enhance exploration\n    min_temperature = 1e-4  # Lower minimum temperature for extended exploration\n\n    best_values = []\n    for _ in range(iterations):\n        if _ % 50 == 0:\n            best_values.append(best_value)\n        # Use historical best values to guide new candidates if needed\n        if len(best_values) > 5 and _ % 200 == 0:\n            candidate_value = min(best_values)\n            if candidate_value < best_value:\n                best_value = candidate_value\n                idx = best_values.index(best_value)\n                current_x, current_y = best_x, best_y\n        # Generate a new candidate point by adding a small perturbation\n        progress_factor = (_ / iterations) ** 0.5  # Adaptive scaling with iteration progress\n        perturbation_scale = max(0.1 * temperature * (1 - progress_factor), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Improved restart mechanism: use best found solutions to guide\n        if _ % 100 == 0 and current_value >= best_value:\n            temperature = 1.0  # Reset temperature to initial value for a fresh start\n            # Introduce randomness to avoid cycling over the same local minima\n            best_x, best_y = np.random.uniform(bounds[0], bounds[1]), np.random.uniform(bounds[0], bounds[1])\n            current_x = best_x + np.random.normal(0, 1)  # Normal distribution for broader exploration\n            current_y = best_y + np.random.normal(0, 1)\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"96538759-e6dd-4e66-9aaf-93c253650715","island":0,"language":"python","metadata":{"changes":"Change 1: Replace perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature with 2 lines\nChange 2: Replace 5 lines with 7 lines\nChange 3: Replace for _ in range(iterations): with 11 lines","parent_metrics":{"combined_score":0.5226791817096981,"distance":2.8885753563887886,"distance_score":0.3197271907925064,"overall_score":0.5045358363419397,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.5337431657486318,"value_score":0.5446017074532435}},"metrics":{"combined_score":0.42022379917416225,"distance":3.777583688551058,"distance_score":0.1715387091046857,"overall_score":0.16404475983483247,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8038628044982474,"value_score":0.44793697740459426},"parent_id":"9d29a7d6-9ffb-4a30-b9f9-f3cb8497870d","timestamp":1747684378.6740701},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        if _ % 100 == 0 and current_value >= best_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"57f20e0e-88a3-4ba4-898f-ee581aac3168","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: Replace temperature = max(temperature * cooling_rate, min_temperature) with 3 lines\nChange 3: Replace 4 lines with 7 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"combined_score":0.433522602887764,"distance":2.2667820605960056,"distance_score":0.24475679833575634,"overall_score":0.4867045205775528,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1516535921724969,"value_score":0.43349260564506187},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683480.6583765},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start simulated annealing and basin hopping.\n    Focuses on exploration and robust escape from local minima.\n    \"\"\"\n    def random_point():\n        return np.random.uniform(bounds[0], bounds[1]), np.random.uniform(bounds[0], bounds[1])\n\n    def clipped(x):\n        return np.clip(x, bounds[0], bounds[1])\n\n    def local_minimize(x0, y0, steps=40, lr=0.02):\n        # Simple gradient descent for local refinement\n        x, y = x0, y0\n        velocity_x, velocity_y = 0, 0\n        for _ in range(steps):\n            grad_x = np.cos(x) * np.cos(y) + y * np.cos(x * y) + x/10\n            grad_y = -np.sin(x) * np.sin(y) + x * np.cos(x * y) + y/10\n            velocity_x = momentum * velocity_x - lr * grad_x\n            velocity_y = momentum * velocity_y - lr * grad_y\n            x = clipped(x + velocity_x)\n            y = clipped(y + velocity_y)\n        return x, y, evaluate_function(x, y)\n\n    n_starts = 8\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Simulated annealing per start\n        current_x, current_y = random_point()\n        current_value = evaluate_function(current_x, current_y)\n        temperature = 3.0\n        cooling_rate = 0.98\n        min_temperature = 1e-4\n        for it in range(iterations // n_starts):\n            perturbation_scale = max(0.25 * temperature, 0.05)\n            new_x = clipped(current_x + np.random.normal(0, perturbation_scale))\n            new_y = clipped(current_y + np.random.normal(0, perturbation_scale))\n            new_value = evaluate_function(new_x, new_y)\n            if new_value < current_value or np.exp((current_value - new_value) / temperature) > np.random.rand():\n                current_x, current_y, current_value = new_x, new_y, new_value\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Basin hopping: after annealing, perform local descent\n        local_x, local_y, local_val = local_minimize(current_x, current_y)\n        if local_val < best_value:\n            best_x, best_y, best_value = local_x, local_y, local_val\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":7,"id":"94d337dc-f6fa-4f96-8616-2dfa715d7441","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'local_minimize(x0, y0, steps=40, lr=0.02):' to 'local_minimize(x0, y0, steps=40, lr=0.02, momentum=0.9):'\nChange 3: Replace for _ in range(steps): with 2 lines\nChange 4: Replace 2 lines with 4 lines\nChange 5: 'n_starts = 8' to 'n_starts = 12  # Increase the number of starts'","parent_metrics":{"distance":1.8307147542726059,"distance_score":0.35326766799467396,"overall_score":0.5,"runs_successfully":1.0,"value":-1.491531269492436,"value_score":0.6201670649980453}},"metrics":{"error":0.0},"parent_id":"f027dd64-4f56-41d8-bb01-4bb6c7065de7","timestamp":1747683786.5489998},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995 + 0.002 * (1 - it / iterations)  # Adaptive cooling\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.1  # Larger step for more aggressive local search\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"1032f518-6add-4c3b-b848-5c4232439b35","island":0,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.995 + 0.002 * (1 - it / iterations)  # Adaptive cooling' to 'cooling_rate = 0.99  # More consistent cooling rate for better convergence'\nChange 2: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.5 * temperature, 0.05)  # Further increase to enhance exploration'\nChange 3: 'if it % 20 == 0:  # More frequent local search' to 'if it % 10 == 0:  # Increase frequency of local search'\nChange 4: 'step = 0.1  # Larger step for more aggressive local search' to 'step = 0.15  # Slightly larger step to improve local search effectiveness'\nChange 5: Replace 5 lines with 6 lines","parent_metrics":{"error":0.0}},"metrics":{"error":0.0},"parent_id":"8dc8fd18-8f8a-4737-b429-761dae9faae4","timestamp":1747684055.405397},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with multiple random points\n    num_initial_points = 5\n    best_x, best_y, best_value = None, None, float('inf')\n    \n    for _ in range(num_initial_points):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.995\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-5  # Lower minimum temperature for finer search\n    no_improvement_count = 0\n    stagnation_limit = 200  # Iterations before considering stagnation\n\n    for i in range(iterations):\n        # Adaptive perturbation based on temperature and distance to the best\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.1, temperature * (1 + distance_to_best * 0.1))\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n\n        # Ensure new points are within bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution and track improvements\n        no_improvement_count += 1\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n            no_improvement_count = 0\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Check for stagnation and adapt cooling rate\n        if no_improvement_count >= stagnation_limit:\n            # Restart with a new random position\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            no_improvement_count = 0\n            temperature = 1.0  # Reset temperature\n            if current_value >= best_value:\n                cooling_rate = max(cooling_rate * 0.95, 0.8 * initial_cooling_rate)  # More exploration\n            else:\n                cooling_rate = min(cooling_rate * 1.05, 1.0)  # Faster convergence\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"2c47e181-1004-4279-9476-50f166783cce","island":0,"language":"python","metadata":{"changes":"Change 1: Replace min_temperature = 1e-5  # Lower minimum temperature for finer search with 2 lines\nChange 2: 'for _ in range(iterations):' to 'for i in range(iterations):'\nChange 3: Replace 6 lines with 9 lines\nChange 4: Replace # Accept the new solution with 2 lines\nChange 5: Replace 3 lines with 3 lines\nChange 6: Replace if _ % stagnation_limit == 0: with 7 lines","parent_metrics":{"combined_score":0.48394963450004286,"distance":2.871764729568233,"distance_score":0.21719792593382894,"overall_score":0.1767899269000086,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1638492058383314,"value_score":0.531317094533157}},"metrics":{"distance":1.7275651375953733,"distance_score":0.3666273579378573,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5181036398848708,"value_score":0.6305582288664843},"parent_id":"7848162a-6e28-4748-994f-25407570d2b5","timestamp":1747684298.5852404},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.98  # Faster cooling to allow better convergence\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = 0.1 * temperature\n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        \n        # Ensure new_x and new_y remain within bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        # Trigger restart if no improvement in last 200 iterations\n        if _ > 0 and _ % 200 == 0 and best_value >= current_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 7 lines\nChange 2: 'cooling_rate = 0.995  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.98  # Faster cooling to allow better convergence'\nChange 3: Replace 5 lines with 5 lines","parent_metrics":{"combined_score":0.3349001626270999,"distance":0.4841698181420444,"distance_score":0.1679899341660393,"overall_score":0.14698003252542,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.1066303074044817,"value_score":0.30750530396214687}},"metrics":{"combined_score":0.35371181446008193,"distance":5.481650992896429,"distance_score":0.1794633008683563,"overall_score":0.15074236289201642,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8806981423956454,"value_score":0.33312137366595845},"parent_id":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","timestamp":1747684000.3388424},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.99  # Adjust cooling rate for better balance\n    min_temperature = 1e-5  # Lower minimum temperature for finer adjustments\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01 * (_ / iterations))  # Adaptive perturbation scale\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Implement restart mechanism with additional condition\n        if _ % 100 == 0 and current_value >= best_value:\n            no_improvement_counter += 1\n        else:\n            no_improvement_counter = 0\n        \n        if no_improvement_counter >= 10:  # Restart if no improvement for 10 cycles\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            no_improvement_counter = 0\n        \n        # Random walk for exploration\n        if _ % 250 == 0:\n            current_x += np.random.uniform(-1, 1)\n            current_y += np.random.uniform(-1, 1)\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"a9e78b1c-441a-4c8f-850c-829628b34b1c","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature' to 'perturbation_scale = max(0.1 * temperature, 0.01 * (_ / iterations))  # Adaptive perturbation scale'\nChange 3: Replace 4 lines with 17 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"error":0.0},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747684161.038598},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved global search algorithm combining Simulated Annealing and Differential Evolution ideas.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Use a population of candidate solutions for diversity\n    pop_size = 10\n    stagnation_limit = 100\n    min_temperature = 1e-6\n\n    population = []\n    for _ in range(pop_size):\n        x = np.random.uniform(bounds[0], bounds[1])\n        y = np.random.uniform(bounds[0], bounds[1])\n        val = evaluate_function(x, y)\n        population.append((x, y, val))\n    # Find initial best\n    population.sort(key=lambda tup: tup[2])\n    best_x, best_y, best_value = population[0]\n    best_iteration = 0\n\n    # Annealing schedule\n    temperature = 2.0\n    cooling_rate = 0.992\n\n    for it in range(iterations):\n        for i in range(pop_size):\n            x0, y0, v0 = population[i]\n            # Differential Evolution-style mutation with random others\n            idxs = list(range(pop_size))\n            idxs.remove(i)\n            a, b, c = population[np.random.choice(idxs)], population[np.random.choice(idxs)], population[np.random.choice(idxs)]\n            F = 0.8\n            mutant_x = np.clip(a[0] + F * (b[0] - c[0]), bounds[0], bounds[1])\n            mutant_y = np.clip(a[1] + F * (b[1] - c[1]), bounds[0], bounds[1])\n\n            # Simulated Annealing-style local perturbation\n            perturb = np.random.normal(0, max(0.1, temperature/2), size=2)\n            trial_x = np.clip(mutant_x + perturb[0], bounds[0], bounds[1])\n            trial_y = np.clip(mutant_y + perturb[1], bounds[0], bounds[1])\n            trial_value = evaluate_function(trial_x, trial_y)\n\n            # Acceptance rule: always accept improvements, otherwise Metropolis\n            if trial_value < v0 or np.exp((v0 - trial_value) / max(temperature, 1e-10)) > np.random.rand():\n                population[i] = (trial_x, trial_y, trial_value)\n                # Update best\n                if trial_value < best_value:\n                    best_x, best_y, best_value = trial_x, trial_y, trial_value\n                    best_iteration = it\n\n        temperature = max(temperature * cooling_rate, min_temperature)\n        # Occasional population re-seeding to escape stagnation\n        if it - best_iteration > stagnation_limit:\n            # Re-seed worst half of population randomly\n            for j in range(pop_size//2, pop_size):\n                x = np.random.uniform(bounds[0], bounds[1])\n                y = np.random.uniform(bounds[0], bounds[1])\n                v = evaluate_function(x, y)\n                population[j] = (x, y, v)\n            # Re-sort\n            population.sort(key=lambda tup: tup[2])\n            best_x, best_y, best_value = population[0]\n            best_iteration = it\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"d8e78925-dc67-44e3-8f33-ecc499720df5","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 63 lines with 71 lines","parent_metrics":{"combined_score":0.48394963450004286,"distance":2.871764729568233,"distance_score":0.21719792593382894,"overall_score":0.1767899269000086,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1638492058383314,"value_score":0.531317094533157}},"metrics":{"distance":1.7056329935562686,"distance_score":0.36959927764837225,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186705060681758,"value_score":0.630783697539033},"parent_id":"7848162a-6e28-4748-994f-25407570d2b5","timestamp":1747684545.4441178},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x, best_y, best_value = None, None, float('inf')\n    n_starts = 5  # Number of random restarts\n\n    for _ in range(n_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995\n\n        for i in range(iterations):\n            # Adaptive perturbation size based on temperature\n            perturbation_size = max(0.1, temperature / 2.0)\n            new_x = current_x + np.random.uniform(-perturbation_size, perturbation_size)\n            new_y = current_y + np.random.uniform(-perturbation_size, perturbation_size)\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            # Accept the new solution\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best solution found\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Dynamic cooling schedule\n            temperature *= cooling_rate * (1 - (i / iterations))\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":2,"id":"706d13f2-4663-46f6-93b6-78fcf043b2db","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 32 lines with 36 lines","parent_metrics":{"combined_score":0.4340846850557817,"distance":6.116510764280398,"distance_score":0.23743554909359196,"overall_score":0.48681693701115636,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6790898014054345,"value_score":0.4380900338795069}},"metrics":{"combined_score":0.5224576607937255,"distance":5.192335910281548,"distance_score":0.22030065048037717,"overall_score":0.18449153215874511,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204747531363051,"value_score":0.5939457760826873},"parent_id":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","timestamp":1747683396.3152523},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1200, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing, random search, evolutionary population, and local search.\n    Enhanced exploration, exploitation, and escape from local minima.\n    \"\"\"\n    n_starts = 25  # More restarts for wider global coverage\n    pop_size = 8   # Population-based search for diversity\n    elite_fraction = 0.25  # Keep top individuals\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize a small population for each restart\n        population = []\n        for _ in range(pop_size):\n            ind_x = np.random.uniform(bounds[0], bounds[1])\n            ind_y = np.random.uniform(bounds[0], bounds[1])\n            ind_value = evaluate_function(ind_x, ind_y)\n            population.append([ind_x, ind_y, ind_value])\n\n        temperature = 2.0\n        cooling_rate = 0.991  # Slightly slower cooling for more exploration\n        min_temperature = 1e-10  # Allow even finer convergence\n\n        patience = 110\n        no_improve_count = 0\n        local_best_value = min(population, key=lambda ind: ind[2])[2]\n\n        for it in range(iterations // n_starts):\n            # Occasionally do a global random jump for some individuals\n            if it % 32 == 0 and np.random.rand() < 0.45:\n                idx = np.random.randint(pop_size)\n                rand_x = np.random.uniform(bounds[0], bounds[1])\n                rand_y = np.random.uniform(bounds[0], bounds[1])\n                rand_value = evaluate_function(rand_x, rand_y)\n                # Accept jump if better or with probability based on temperature\n                if rand_value < population[idx][2] or np.exp((population[idx][2] - rand_value) / (temperature+1e-12)) > np.random.rand():\n                    population[idx] = [rand_x, rand_y, rand_value]\n                    if rand_value < best_value:\n                        best_x, best_y, best_value = rand_x, rand_y, rand_value\n                    no_improve_count = 0\n\n            # Evolutionary/mutation step for population diversity\n            new_population = []\n            for ind in population:\n                # Candidate generation: Gaussian perturbation\n                perturbation_scale = max(0.45 * temperature, 0.01)\n                if np.random.rand() < 0.7:\n                    new_x = ind[0] + np.random.normal(0, perturbation_scale)\n                    new_y = ind[1] + np.random.normal(0, perturbation_scale)\n                else:\n                    # Crossover/combination with another random individual\n                    mate = population[np.random.randint(pop_size)]\n                    alpha = np.random.uniform(-0.2, 1.2)\n                    new_x = alpha * ind[0] + (1 - alpha) * mate[0]\n                    new_y = alpha * ind[1] + (1 - alpha) * mate[1]\n                    new_x += np.random.normal(0, perturbation_scale/2)\n                    new_y += np.random.normal(0, perturbation_scale/2)\n                new_x = np.clip(new_x, bounds[0], bounds[1])\n                new_y = np.clip(new_y, bounds[0], bounds[1])\n                new_value = evaluate_function(new_x, new_y)\n                # Simulated annealing acceptance\n                if new_value < ind[2]:\n                    accept = True\n                else:\n                    accept = np.exp((ind[2] - new_value) / (temperature+1e-12)) > np.random.rand()\n                if accept:\n                    new_population.append([new_x, new_y, new_value])\n                else:\n                    new_population.append(ind)\n\n            # Local search: gradient step on the current best in the population\n            if it % 9 == 0:\n                elite = sorted(new_population, key=lambda ind: ind[2])[:max(1,int(elite_fraction*pop_size))]\n                for e in elite:\n                    grad_eps = 1e-5\n                    grad_x = (evaluate_function(e[0] + grad_eps, e[1]) - e[2]) / grad_eps\n                    grad_y = (evaluate_function(e[0], e[1] + grad_eps) - e[2]) / grad_eps\n                    grad_norm = np.sqrt(grad_x**2 + grad_y**2) + 1e-8\n                    step = min(0.12, 0.7 * temperature/2) / grad_norm  # Slightly larger adaptive step\n                    trial_x = np.clip(e[0] - step * grad_x, bounds[0], bounds[1])\n                    trial_y = np.clip(e[1] - step * grad_y, bounds[0], bounds[1])\n                    trial_value = evaluate_function(trial_x, trial_y)\n                    if trial_value < e[2]:\n                        e[0], e[1], e[2] = trial_x, trial_y, trial_value\n\n            # Survivor selection: keep best, encourage diversity\n            population = sorted(new_population, key=lambda ind: ind[2])\n            # Replace worst with randoms to keep exploration\n            for i in range(int(pop_size*0.18)):\n                rand_x = np.random.uniform(bounds[0], bounds[1])\n                rand_y = np.random.uniform(bounds[0], bounds[1])\n                rand_value = evaluate_function(rand_x, rand_y)\n                population[-(i+1)] = [rand_x, rand_y, rand_value]\n            # Best solution in this generation\n            gen_best = population[0]\n            if gen_best[2] < best_value:\n                best_x, best_y, best_value = gen_best[0], gen_best[1], gen_best[2]\n                no_improve_count = 0\n            elif gen_best[2] < local_best_value:\n                local_best_value = gen_best[2]\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # If stuck, re-initialize part of the population (adaptive restart)\n            if no_improve_count > patience:\n                for i in range(int(pop_size//2)):\n                    population[i][0] = np.random.uniform(bounds[0], bounds[1])\n                    population[i][1] = np.random.uniform(bounds[0], bounds[1])\n                    population[i][2] = evaluate_function(population[i][0], population[i][1])\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":8,"id":"cac2b03c-4c1a-4848-bcfa-6f4e441f69dc","island":0,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 3 lines\nChange 2: 'pop_size = 8   # Population-based search for diversity' to 'pop_size = 10  # Increase initial population for better exploration'\nChange 3: Replace step = min(0.12, 0.7 * temperature/2) / grad_norm  # Slightly larger adaptive step with 2 lines","parent_metrics":{"distance":1.7014649692958308,"distance_score":0.37016952333853953,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5185893457006194,"value_score":0.6307514064499059}},"metrics":{"distance":1.7240316862310823,"distance_score":0.36710292507044245,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5172406439068133,"value_score":0.6302152851092263},"parent_id":"97cdc700-2675-4141-87a5-dcf93f95bba0","timestamp":1747683863.3988867},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1200, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing, random search, evolutionary population, and local search.\n    Enhanced exploration, exploitation, and escape from local minima.\n    \"\"\"\n    n_starts = 25  # More restarts for wider global coverage\n    pop_size = 8   # Population-based search for diversity\n    elite_fraction = 0.25  # Keep top individuals\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize a small population for each restart\n        population = []\n        for _ in range(pop_size):\n            ind_x = np.random.uniform(bounds[0], bounds[1])\n            ind_y = np.random.uniform(bounds[0], bounds[1])\n            ind_value = evaluate_function(ind_x, ind_y)\n            population.append([ind_x, ind_y, ind_value])\n\n        temperature = 2.0\n        cooling_rate = 0.991  # Slightly slower cooling for more exploration\n        min_temperature = 1e-10  # Allow even finer convergence\n\n        patience = 110\n        no_improve_count = 0\n        local_best_value = min(population, key=lambda ind: ind[2])[2]\n\n        for it in range(iterations // n_starts):\n            # Occasionally do a global random jump for some individuals\n            if it % 32 == 0 and np.random.rand() < 0.45:\n                idx = np.random.randint(pop_size)\n                rand_x = np.random.uniform(bounds[0], bounds[1])\n                rand_y = np.random.uniform(bounds[0], bounds[1])\n                rand_value = evaluate_function(rand_x, rand_y)\n                # Accept jump if better or with probability based on temperature\n                if rand_value < population[idx][2] or np.exp((population[idx][2] - rand_value) / (temperature+1e-12)) > np.random.rand():\n                    population[idx] = [rand_x, rand_y, rand_value]\n                    if rand_value < best_value:\n                        best_x, best_y, best_value = rand_x, rand_y, rand_value\n                    no_improve_count = 0\n\n            # Evolutionary/mutation step for population diversity\n            new_population = []\n            for ind in population:\n                # Candidate generation: Gaussian perturbation\n                perturbation_scale = max(0.45 * temperature, 0.01)\n                if np.random.rand() < 0.7:\n                    new_x = ind[0] + np.random.normal(0, perturbation_scale)\n                    new_y = ind[1] + np.random.normal(0, perturbation_scale)\n                else:\n                    # Crossover/combination with another random individual\n                    mate = population[np.random.randint(pop_size)]\n                    alpha = np.random.uniform(-0.2, 1.2)\n                    new_x = alpha * ind[0] + (1 - alpha) * mate[0]\n                    new_y = alpha * ind[1] + (1 - alpha) * mate[1]\n                    new_x += np.random.normal(0, perturbation_scale/2)\n                    new_y += np.random.normal(0, perturbation_scale/2)\n                new_x = np.clip(new_x, bounds[0], bounds[1])\n                new_y = np.clip(new_y, bounds[0], bounds[1])\n                new_value = evaluate_function(new_x, new_y)\n                # Simulated annealing acceptance\n                if new_value < ind[2]:\n                    accept = True\n                else:\n                    accept = np.exp((ind[2] - new_value) / (temperature+1e-12)) > np.random.rand()\n                if accept:\n                    new_population.append([new_x, new_y, new_value])\n                else:\n                    new_population.append(ind)\n\n            # Local search: gradient step on the current best in the population\n            if it % 9 == 0:\n                elite = sorted(new_population, key=lambda ind: ind[2])[:max(1,int(elite_fraction*pop_size))]\n                for e in elite:\n                    grad_eps = 1e-5\n                    grad_x = (evaluate_function(e[0] + grad_eps, e[1]) - e[2]) / grad_eps\n                    grad_y = (evaluate_function(e[0], e[1] + grad_eps) - e[2]) / grad_eps\n                    grad_norm = np.sqrt(grad_x**2 + grad_y**2) + 1e-8\n                    step = min(0.12, 0.7 * temperature/2) / grad_norm  # Slightly larger adaptive step\n                    trial_x = np.clip(e[0] - step * grad_x, bounds[0], bounds[1])\n                    trial_y = np.clip(e[1] - step * grad_y, bounds[0], bounds[1])\n                    trial_value = evaluate_function(trial_x, trial_y)\n                    if trial_value < e[2]:\n                        e[0], e[1], e[2] = trial_x, trial_y, trial_value\n\n            # Survivor selection: keep best, encourage diversity\n            population = sorted(new_population, key=lambda ind: ind[2])\n            # Replace worst with randoms to keep exploration\n            for i in range(int(pop_size*0.18)):\n                rand_x = np.random.uniform(bounds[0], bounds[1])\n                rand_y = np.random.uniform(bounds[0], bounds[1])\n                rand_value = evaluate_function(rand_x, rand_y)\n                population[-(i+1)] = [rand_x, rand_y, rand_value]\n            # Best solution in this generation\n            gen_best = population[0]\n            if gen_best[2] < best_value:\n                best_x, best_y, best_value = gen_best[0], gen_best[1], gen_best[2]\n                no_improve_count = 0\n            elif gen_best[2] < local_best_value:\n                local_best_value = gen_best[2]\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # If stuck, re-initialize part of the population (adaptive restart)\n            if no_improve_count > patience:\n                for i in range(int(pop_size//2)):\n                    population[i][0] = np.random.uniform(bounds[0], bounds[1])\n                    population[i][1] = np.random.uniform(bounds[0], bounds[1])\n                    population[i][2] = evaluate_function(population[i][0], population[i][1])\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":7,"id":"97cdc700-2675-4141-87a5-dcf93f95bba0","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 87 lines with 115 lines","parent_metrics":{"distance":1.7365245964003113,"distance_score":0.36542700961483165,"overall_score":0.5,"runs_successfully":1.0,"value":-1.4989040660672401,"value_score":0.6230157206552936}},"metrics":{"distance":1.7014649692958308,"distance_score":0.37016952333853953,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5185893457006194,"value_score":0.6307514064499059},"parent_id":"350e2a5b-a4bb-49eb-91ba-d8428603711d","timestamp":1747683712.8119185},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.999\n    min_temperature = 1e-4  # Allow for a lower minimum temperature for finer search\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Random restart mechanism\n        if _ > 0 and _ % adaptive_cooling_threshold == 0:\n            if np.random.rand() < 0.5:  # 50% chance to restart\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        # Dynamically adjust the cooling rate\n        cooling_rate = initial_cooling_rate * (0.5 + 0.5 * np.cos(np.pi * _ / iterations))\n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"d819021f-e261-4988-80e6-fa7c521f68e1","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 8 lines with 6 lines\nChange 2: 'cooling_rate = 0.999  # Use a slightly slower cooling rate initially' to 'initial_cooling_rate = 0.999'\nChange 3: Replace temperature = max(temperature * cooling_rate, min_temperature) with 3 lines\nChange 4: 'perturbation_scale = max(0.1 * np.exp(-_ / 100) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)' to 'perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)'","parent_metrics":{"combined_score":0.34214512427689625,"distance":4.743031487484652,"distance_score":0.20122546018725854,"overall_score":0.1484290248553793,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.634261755501169,"value_score":0.30296247703453116}},"metrics":{"combined_score":0.47993143926861664,"distance":5.1890139004496065,"distance_score":0.2764172543253523,"overall_score":0.49598628785372334,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204993892200068,"value_score":0.4950104382850183},"parent_id":"ce21b5d0-3f22-435a-8b44-e20416b9d464","timestamp":1747684014.6612341},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution and update momentum\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update momentum\n            momentum = momentum_factor * momentum + np.array([new_x - current_x, new_y - current_y])\n        else:\n            # Reset momentum on rejection\n            momentum = np.array([0.0, 0.0])\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Adaptive cooling schedule\n        if current_value < best_value:\n            temperature = max(temperature * adaptive_rate, min_temperature)\n        else:\n            # Increase temperature if stuck in a local minimum\n            temperature = min(temperature * temperature_increase, 1.0)\n\n        # Improved restart mechanism\n        if _ % 200 == 0 and current_value >= best_value:\n            # Use a strategic restart by slightly perturbing the best known solution\n            current_x = best_x + np.random.uniform(-1, 1)\n            current_y = best_y + np.random.uniform(-1, 1)\n            current_value = evaluate_function(current_x, current_y)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"6bec508a-f78b-4291-9af6-4d6a37384980","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 6 lines\nChange 2: Replace 2 lines with 8 lines\nChange 3: '# Accept the new solution' to '# Accept the new solution and update momentum'\nChange 4: Replace # Update the best solution found with 7 lines\nChange 5: Replace 8 lines with 13 lines","parent_metrics":{"combined_score":0.41411306444653023,"distance":2.4411503423243888,"distance_score":0.18678802902100744,"overall_score":0.16282261288930605,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8738212402463125,"value_score":0.43012775956704674}},"metrics":{"error":0.0},"parent_id":"378c023c-827e-4016-b9de-265020c5e8dd","timestamp":1747683613.8497512},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Random restart function to initialize a new search point\n    def random_restart():\n        return (np.random.uniform(bounds[0], bounds[1]), \n                np.random.uniform(bounds[0], bounds[1]), \n                float('inf'))  # Start with a high value to ensure any real evaluation is better\n\n    # Initialize with a random point\n    current_x, current_y, current_value = random_restart()\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.99  # Adjust cooling rate for better exploration\n    min_temperature = 1e-3\n    no_improvement_threshold = 200  # Number of iterations to trigger a restart\n    last_improvement_iteration = 0  # Track the last improvement\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.05)  # Adjusted to allow broader exploration\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Check for improvement\n        if current_value < best_value:\n            last_improvement_iteration = _  # Update last improvement\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Restart if no improvement\n        if _ - last_improvement_iteration > no_improvement_threshold:\n            current_x, current_y, current_value = random_restart()\n            last_improvement_iteration = _  # Reset improvement tracker\n\n        # Perform a local search step after a restart\n        if _ % no_improvement_threshold == 0:\n            gradient_step = 0.01  # Small step for local search\n            grad_x = np.cos(current_x) * np.cos(current_y) + y * np.cos(current_x * current_y)\n            grad_y = -np.sin(current_x) * np.sin(current_y) + x * np.cos(current_x * current_y)\n            current_x -= gradient_step * grad_x\n            current_y -= gradient_step * grad_y\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"4f47720f-4f9d-43e1-b1f1-1eda6708c5e3","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 4 lines with 8 lines\nChange 2: Replace 3 lines with 5 lines\nChange 3: 'perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature' to 'perturbation_scale = max(0.1 * temperature, 0.05)  # Adjusted to allow broader exploration'\nChange 4: Replace 5 lines with 18 lines","parent_metrics":{"combined_score":0.41411306444653023,"distance":2.4411503423243888,"distance_score":0.18678802902100744,"overall_score":0.16282261288930605,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8738212402463125,"value_score":0.43012775956704674}},"metrics":{"error":0.0},"parent_id":"378c023c-827e-4016-b9de-265020c5e8dd","timestamp":1747683456.1414762},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A robust global optimization algorithm combining multi-start, simulated annealing, and random restarts.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: run several independent simulated annealing searches\n    n_starts = 15  # Further increased for comprehensive exploration\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n\n        temperature = 2.5  # Slightly higher starting temperature\n        initial_cooling_rate = 0.99\n        cooling_rate = initial_cooling_rate\n        # Adapt cooling rate based on progress\n        if no_improve_count > (iterations // (4 * n_starts)):\n            cooling_rate = 0.95  # Faster cooling if stuck\n        elif i < (iterations // (4 * n_starts)):\n            cooling_rate = 0.995  # Slower cooling in early stages\n        min_temperature = 1e-4\n\n        no_improve_count = 0\n        last_improve_iter = 0\n        max_no_improve = iterations // 8  # Trigger restart if stuck\n\n        for i in range(iterations // n_starts):\n            # Generate a new candidate point by adding a scaled perturbation\n            # Adjust perturbation based on current temperature and progress\n            perturbation_scale = max(0.5 * temperature, 0.1 * (1 - (i / iterations)))\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n            # Ensure inside bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            if current_value < local_best_value:\n                local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n                no_improve_count = 0\n                last_improve_iter = i\n            else:\n                no_improve_count += 1\n\n            # Random restart if no improvement for several iterations\n            # Dynamic restart based on improvement rate\n            if no_improve_count > max_no_improve or (i - last_improve_iter) > iterations // (2 * n_starts):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Update best found across all starts\n        if local_best_value < best_value:\n            best_x, best_y, best_value = local_best_x, local_best_y, local_best_value\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"efccd91b-297f-4029-b9f9-effe9a3f538e","island":1,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 10  # Increased for better exploration' to 'n_starts = 15  # Further increased for comprehensive exploration'\nChange 2: Replace cooling_rate = 0.99  # Adjusted for smoother cooling with 7 lines\nChange 3: Replace perturbation_scale = max(0.5 * temperature, 0.05)  # Adjusted minimum scale with 2 lines","parent_metrics":{"distance":1.7924826056410745,"distance_score":0.3581042897026133,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5007780014193184,"value_score":0.6237439362017807}},"metrics":{"error":0.0},"parent_id":"df745310-83ff-4a2f-b5c6-bb524df03055","timestamp":1747684066.9202192},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        if _ % 100 == 0 and current_value >= best_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"378c023c-827e-4016-b9de-265020c5e8dd","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 3 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature' to 'perturbation_scale = max(0.1 * temperature * (1 - _ / iterations), 0.01)  # Dynamic scaling'\nChange 3: Replace if _ % 100 == 0 and current_value >= best_value: with 10 lines\nChange 4: Replace temperature = max(temperature * cooling_rate, min_temperature) with 3 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"combined_score":0.41411306444653023,"distance":2.4411503423243888,"distance_score":0.18678802902100744,"overall_score":0.16282261288930605,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8738212402463125,"value_score":0.43012775956704674},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683373.4705305},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multi-start with simulated annealing and periodic global jumps.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: Try several different initial points, keep the best\n    num_starts = 5\n    best_x, best_y, best_value = None, None, np.inf\n    for start in range(num_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        temperature = 2.0  # Higher initial temperature for more exploration\n        min_temperature = 1e-5\n        cooling_rate = 0.995\n        perturbation_scale_init = (bounds[1] - bounds[0]) * 0.1\n        stagnation_counter = 0\n        last_improvement = current_value\n        for i in range(iterations // num_starts):\n            # Adaptive perturbation: scale with temperature\n            perturbation_scale = max(perturbation_scale_init * temperature, 0.01)\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n            # Keep within bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            # Acceptance logic\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / (temperature + 1e-8)) > np.random.rand()\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                # Stagnation detection for global jump\n                if new_value < last_improvement - 1e-6:\n                    last_improvement = new_value\n                    stagnation_counter = 0\n                else:\n                    stagnation_counter += 1\n            else:\n                stagnation_counter += 1\n            # Update best found\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n            # Global jump if stagnating\n            if stagnation_counter >= 60:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                stagnation_counter = 0\n                last_improvement = current_value\n            # Periodic global jump (random restart) to escape deep local minima\n            if i > 0 and i % 120 == 0:\n                if np.random.rand() < 0.25:\n                    current_x = np.random.uniform(bounds[0], bounds[1])\n                    current_y = np.random.uniform(bounds[0], bounds[1])\n                    current_value = evaluate_function(current_x, current_y)\n                    stagnation_counter = 0\n                    last_improvement = current_value\n            # Cool down\n            temperature = max(temperature * cooling_rate, min_temperature)\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":7,"id":"eac7b8ae-c8cd-4104-925d-360521561854","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 61 lines with 68 lines","parent_metrics":{"combined_score":0.4172396264418222,"distance":5.098756851702309,"distance_score":0.19629328792569578,"overall_score":0.16344792528836447,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.3292443516039463,"value_score":0.4305860667735226}},"metrics":{"distance":1.618433327347625,"distance_score":0.38190775741957217,"overall_score":0.5,"runs_successfully":1.0,"value":-1.492414963630379,"value_score":0.6205071264825566},"parent_id":"c8d7f975-d28d-4d6d-9e7a-581a88a1ad10","timestamp":1747684355.272367},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start simulated annealing and basin hopping.\n    Focuses on exploration and robust escape from local minima.\n    \"\"\"\n    def random_point():\n        return np.random.uniform(bounds[0], bounds[1]), np.random.uniform(bounds[0], bounds[1])\n\n    def clipped(x):\n        return np.clip(x, bounds[0], bounds[1])\n\n    def local_minimize(x0, y0, steps=40, initial_lr=0.02):\n        # Adaptive learning rate\n        lr = initial_lr\n        # Simple gradient descent for local refinement\n        x, y = x0, y0\n        velocity_x, velocity_y = 0, 0\n        momentum = 0.9  # Introduce momentum to accelerate convergence\n        for _ in range(steps + 20):  # Increase the number of steps for better convergence\n            grad_x = np.cos(x) * np.cos(y) + y * np.cos(x * y) + x/10\n            grad_y = -np.sin(x) * np.sin(y) + x * np.cos(x * y) + y/10\n            velocity_x = momentum * velocity_x - lr * grad_x\n            velocity_y = momentum * velocity_y - lr * grad_y\n            x = clipped(x + velocity_x)\n            y = clipped(y + velocity_y)\n            lr *= 0.95  # Decrease learning rate to improve convergence\n        return x, y, evaluate_function(x, y)\n\n    n_starts = 12  # Increase the number of starts for better exploration\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Simulated annealing per start\n        current_x, current_y = random_point()\n        current_value = evaluate_function(current_x, current_y)\n        temperature = 2.0\n        cooling_rate = 0.98 if temperature > 1 else 0.995  # Dynamic cooling rate\n        min_temperature = 1e-4\n        for it in range(iterations // n_starts):\n            perturbation_scale = max(0.25 * temperature, 0.05)\n            new_x = clipped(current_x + np.random.uniform(-perturbation_scale, perturbation_scale))\n            new_y = clipped(current_y + np.random.uniform(-perturbation_scale, perturbation_scale))\n            new_value = evaluate_function(new_x, new_y)\n            if new_value < current_value or np.exp((current_value - new_value) / temperature) > np.random.rand():\n                current_x, current_y, current_value = new_x, new_y, new_value\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Basin hopping: after annealing, perform local descent\n        local_x, local_y, local_val = local_minimize(current_x, current_y)\n        if local_val < best_value:\n            best_x, best_y, best_value = local_x, local_y, local_val\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":7,"id":"15d74e04-bf8f-4e19-afc2-835e27ac00d7","island":1,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.25 * temperature, 0.05)' to 'perturbation_scale = max(0.5 * temperature, 0.05)  # Increase exploration capability'\nChange 2: Replace for _ in range(steps): with 3 lines\nChange 3: Replace 2 lines with 4 lines","parent_metrics":{"distance":1.4336776251968648,"distance_score":0.4109007658395627,"overall_score":0.5,"runs_successfully":1.0,"value":-1.1112634396505654,"value_score":0.5018224786444656}},"metrics":{"distance":1.7186072068781202,"distance_score":0.3678354112613193,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5185020733040537,"value_score":0.6307166872705546},"parent_id":"c6fea3a7-8022-4565-9641-2f9496ccbd12","timestamp":1747684310.4544604},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.99  # Slower cooling for more exploration\n        min_temperature = 1e-8  # Even lower minimum temperature for finer convergence\n\n        patience = max(60, int(80 * (1 - temperature)))  # Dynamic patience based on temperature\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts * 2):  # Increase iterations for deeper search in each restart\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.5 * temperature, 0.01) * (1 + np.random.uniform(-0.2, 0.2))  # Increase and randomize perturbation scale more\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.05\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience or temperature < 0.05:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            # Adaptive cooling schedule based on progress\n            if it % 50 == 0 and no_improve_count > patience // 2:\n                cooling_rate *= 0.9  # Slow down cooling if stuck\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"955314df-ad43-4b3b-a59c-f964427d379f","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'for it in range(iterations // n_starts):' to 'for it in range(iterations // n_starts * 2):  # Increase iterations for deeper search in each restart'\nChange 3: 'perturbation_scale = max(0.4 * temperature, 0.02) * (1 + np.random.uniform(-0.1, 0.1))  # Randomize perturbation scale' to 'perturbation_scale = max(0.5 * temperature, 0.01) * (1 + np.random.uniform(-0.2, 0.2))  # Increase and randomize perturbation scale more'\nChange 4: Replace temperature = max(temperature * cooling_rate, min_temperature) with 4 lines","parent_metrics":{"distance":1.7586767044220888,"distance_score":0.36249263945899324,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5137266826113325,"value_score":0.6288227244119678}},"metrics":{"distance":1.705403322863378,"distance_score":0.3696306541612463,"overall_score":0.5,"runs_successfully":1.0,"value":-1.518071800903431,"value_score":0.6305455698244438},"parent_id":"2564795d-fa97-48bc-9235-9beda242ee38","timestamp":1747684239.6475923},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with multiple random points\n    num_initial_points = 5\n    best_x, best_y, best_value = None, None, float('inf')\n    \n    for _ in range(num_initial_points):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.995\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-5  # Lower minimum temperature for finer search\n    stagnation_limit = 200  # Iterations before considering stagnation\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.1, temperature * distance_to_best * 0.1)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Check for stagnation and adapt cooling rate\n        if _ % stagnation_limit == 0:\n            if current_value >= best_value:\n                cooling_rate = max(cooling_rate * 0.95, 0.8 * initial_cooling_rate)  # More exploration\n            else:\n                cooling_rate = min(cooling_rate * 1.05, 1.0)  # Faster convergence\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"7848162a-6e28-4748-994f-25407570d2b5","island":1,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.05)' to 'perturbation_scale = max(0.1, temperature * distance_to_best * 0.1)'\nChange 2: Replace 11 lines with 5 lines\nChange 3: Replace 6 lines with 11 lines","parent_metrics":{"combined_score":0.4486355733848136,"distance":0.8036624705482555,"distance_score":0.22602127933344787,"overall_score":0.16972711467696272,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.29619770166506365,"value_score":0.46804864930796547}},"metrics":{"combined_score":0.48394963450004286,"distance":2.871764729568233,"distance_score":0.21719792593382894,"overall_score":0.1767899269000086,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1638492058383314,"value_score":0.531317094533157},"parent_id":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","timestamp":1747684216.584651},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.98  # Adjust the initial cooling rate for more aggressive cooling\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-4  # Lower minimum temperature to allow more exploration\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Use fixed scale with Gaussian perturbation\n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Adaptive restart mechanism with stagnation detection\n        if _ % 50 == 0:  # Check more frequently\n            if current_value >= best_value - 1e-6:  # Check for stagnation with a small tolerance\n                restart_probability = 0.1  # Constant probability for restart to prevent being trapped\n                if np.random.rand() < restart_probability:\n                    # Random restart with a slight bias towards previous best\n                    current_x = best_x + np.random.normal(0, 0.5)\n                    current_y = best_y + np.random.normal(0, 0.5)\n                    current_value = evaluate_function(current_x, current_y)\n                # Dynamic cooling rate adjustment based on recent progress\n                cooling_rate = initial_cooling_rate * (0.8 + 0.2 * (_ / iterations))\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"c843ba2e-3257-4af0-8b9d-7efddbd7f187","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 3 lines\nChange 2: Replace 3 lines with 3 lines\nChange 3: Replace 9 lines with 10 lines","parent_metrics":{"combined_score":0.4468310157834882,"distance":6.071918133930994,"distance_score":0.20175500454188094,"overall_score":0.48936620315669765,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9282770999302274,"value_score":0.47717419070153994}},"metrics":{"combined_score":0.4079765577329701,"distance":3.751892013383784,"distance_score":0.2099846123058371,"overall_score":0.4815953115465941,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.23625004774354164,"value_score":0.40830195673536496},"parent_id":"8a86605a-8bc7-4c6c-a0a3-f4fdee4883bb","timestamp":1747684561.6174774},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        if _ % 100 == 0 and current_value >= best_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":2,"id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 3 lines\nChange 2: Replace 2 lines with 3 lines\nChange 3: Replace temperature *= cooling_rate with 7 lines","parent_metrics":{"combined_score":0.4340846850557817,"distance":6.116510764280398,"distance_score":0.23743554909359196,"overall_score":0.48681693701115636,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6790898014054345,"value_score":0.4380900338795069}},"metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378},"parent_id":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","timestamp":1747683323.0795488},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.998  # Slow down cooling to enhance exploration\n    min_temperature = 1e-4  # Lower minimum temperature for extended exploration\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Improved restart mechanism: use best found solutions to guide\n        if _ % 100 == 0 and current_value >= best_value:\n            temperature = 1.0  # Reset temperature to initial value for a fresh start\n            current_x = best_x + np.random.uniform(-1, 1)  # Small perturbation around best\n            current_y = best_y + np.random.uniform(-1, 1)\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"9d29a7d6-9ffb-4a30-b9f9-f3cb8497870d","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: Replace perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature with 2 lines\nChange 3: Replace 3 lines with 5 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"combined_score":0.5226791817096981,"distance":2.8885753563887886,"distance_score":0.3197271907925064,"overall_score":0.5045358363419397,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.5337431657486318,"value_score":0.5446017074532435},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747684340.302135},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly faster cooling rate to allow more exploration initially\n    min_temperature = 1e-4  # Allow for a lower minimum temperature for finer search\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        improvement_factor = max(0.1, min(1.0, 1.0 / (1.0 + np.abs(best_value - current_value))))\n        perturbation_scale = max(0.1 * improvement_factor * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate dynamic acceptance probability\n        accept_probability = np.exp((current_value - new_value) / (temperature * (1 + 0.01 * _)))\n        if new_value < current_value or accept_probability > np.random.rand():\n            accept = True\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Enhanced restart mechanism\n        if _ > 0 and _ % adaptive_cooling_threshold == 0:\n            if best_value >= current_value:\n                if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                    # Restart with a focus on unexplored regions\n                    current_x = best_x + np.random.uniform(-1, 1)\n                    current_y = best_y + np.random.uniform(-1, 1)\n                    current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"15bbf12b-fd48-497e-8edc-2f6a878021db","island":1,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.999  # Use a slightly slower cooling rate initially' to 'cooling_rate = 0.995  # Slightly faster cooling rate to allow more exploration initially'\nChange 2: Replace perturbation_scale = max(0.1 * np.exp(-_ / 100) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01) with 2 lines\nChange 3: Replace 5 lines with 4 lines","parent_metrics":{"combined_score":0.34214512427689625,"distance":4.743031487484652,"distance_score":0.20122546018725854,"overall_score":0.1484290248553793,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.634261755501169,"value_score":0.30296247703453116}},"metrics":{"distance":1.8118133600409143,"distance_score":0.35564238160723766,"overall_score":0.5,"runs_successfully":1.0,"value":-1.355661110580116,"value_score":0.5719714902251072},"parent_id":"ce21b5d0-3f22-435a-8b44-e20416b9d464","timestamp":1747684600.8558173},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global function minimization using multi-start Simulated Annealing with periodic large jumps.\n    \"\"\"\n    # Multi-start strategy: try multiple different initial points\n    n_starts = 5\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n\n        # Annealing parameters for each run\n        temperature = 2.0\n        cooling_rate = 0.985\n        min_temperature = 1e-4\n        no_improve_counter = 0\n        best_local_x, best_local_y, best_local_value = current_x, current_y, current_value\n\n        for i in range(iterations // n_starts):\n            # Adaptive perturbation: small steps most of the time, large steps occasionally to escape local minima\n            if i % 100 == 0 and i > 0:\n                # Large random jump\n                new_x = np.random.uniform(bounds[0], bounds[1])\n                new_y = np.random.uniform(bounds[0], bounds[1])\n            else:\n                # Anneal with adaptive step size\n                step_scale = 0.2 * temperature + 0.05\n                new_x = current_x + np.random.normal(0, step_scale)\n                new_y = current_y + np.random.normal(0, step_scale)\n                new_x = np.clip(new_x, bounds[0], bounds[1])\n                new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Accept with probability based on SA\n            if new_value < current_value:\n                accept = True\n            else:\n                delta = (current_value - new_value)\n                accept = np.exp(delta / temperature) > np.random.rand()\n\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                if current_value < best_local_value:\n                    best_local_x, best_local_y, best_local_value = current_x, current_y, current_value\n                    no_improve_counter = 0\n                else:\n                    no_improve_counter += 1\n            else:\n                no_improve_counter += 1\n\n            # Random re-start if stuck for a long time\n            if no_improve_counter > 80:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_counter = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Update overall best\n        if best_local_value < best_value:\n            best_x, best_y, best_value = best_local_x, best_local_y, best_local_value\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"81c191d8-75d4-4bb7-b287-f408e13afef2","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 59 lines with 67 lines","parent_metrics":{"combined_score":0.35371181446008193,"distance":5.481650992896429,"distance_score":0.1794633008683563,"overall_score":0.15074236289201642,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8806981423956454,"value_score":0.33312137366595845}},"metrics":{"distance":1.828114989724455,"distance_score":0.35359241177722783,"overall_score":0.5,"runs_successfully":1.0,"value":-1.4683318961503105,"value_score":0.6113709729048402},"parent_id":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","timestamp":1747684469.8824012},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995  # Slightly slower cooling for more exploration\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.05\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"fbc34e4f-c22a-4e83-9d2b-3cbaa8ad7608","island":1,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.995  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.999  # Slower cooling to maintain exploration longer'\nChange 2: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.5 * temperature, 0.05)  # Increase scale for more significant jumps'\nChange 3: 'accept = np.exp((current_value - new_value) / temperature) > np.random.rand()' to 'accept = np.exp((current_value - new_value) / (temperature * 0.5)) > np.random.rand()'\nChange 4: 'n_starts = 10  # Increase number of random restarts' to 'n_starts = 20  # Further increase number of random restarts for better exploration'\nChange 5: 'step = 0.05' to 'step = 0.1  # Increase step size for local search'","parent_metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014}},"metrics":{"distance":1.6149312762401669,"distance_score":0.3824192280256911,"overall_score":0.5,"runs_successfully":1.0,"value":-1.4981511396923075,"value_score":0.6227236103704009},"parent_id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","timestamp":1747683539.7931006},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.99\n\n    no_improvement_count = 0\n    max_no_improvement = 100\n\n    for _ in range(iterations):\n        if no_improvement_count >= max_no_improvement:\n            # Restart from a new random position\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            no_improvement_count = 0\n        # Generate a new candidate point by adding a small perturbation\n        step_size = 0.1 * temperature\n        new_x = current_x + np.random.uniform(-step_size, step_size)\n        new_y = current_y + np.random.uniform(-step_size, step_size)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Dynamic cooling based on improvement\n        if accept and new_value < best_value:\n            cooling_rate = 0.99  # Faster cooling\n        else:\n            cooling_rate = 0.999  # Slower cooling\n\n        temperature *= cooling_rate\n\n        if current_value < best_value:\n            no_improvement_count = 0\n        else:\n            no_improvement_count += 1\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":2,"id":"cb0c3484-4358-4e0e-ace7-0f479fedf88f","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 3 lines\nChange 2: Replace for _ in range(iterations): with 10 lines\nChange 3: Replace 2 lines with 12 lines","parent_metrics":{"combined_score":0.4340846850557817,"distance":6.116510764280398,"distance_score":0.23743554909359196,"overall_score":0.48681693701115636,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6790898014054345,"value_score":0.4380900338795069}},"metrics":{"combined_score":0.4480630859622973,"distance":1.8675106599928426,"distance_score":0.21300873216932784,"overall_score":0.16961261719245949,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.148360291462576,"value_score":0.4736007771858317},"parent_id":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","timestamp":1747684729.4667482},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x, best_y, best_value = None, None, float('inf')\n    n_starts = 10  # Increase number of random restarts\n\n    for _ in range(n_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.999  # Adjust cooling rate for slower cooling\n\n        for i in range(iterations):\n            # Adaptive perturbation size based on temperature\n            # Allow larger perturbations initially\n            perturbation_size = max(0.1, temperature / 1.5)\n            new_x = current_x + np.random.uniform(-perturbation_size, perturbation_size)\n            new_y = current_y + np.random.uniform(-perturbation_size, perturbation_size)\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            # Accept the new solution\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best solution found\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Dynamic cooling schedule\n            temperature *= cooling_rate * (1 - (i / iterations))\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"e9301cf9-0400-4cd3-ae96-5faa712febab","island":1,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 5  # Number of random restarts' to 'n_starts = 10  # Increase number of random restarts'\nChange 2: 'cooling_rate = 0.995' to 'cooling_rate = 0.999  # Adjust cooling rate for slower cooling'\nChange 3: Replace perturbation_size = max(0.1, temperature / 2.0) with 2 lines","parent_metrics":{"combined_score":0.5224576607937255,"distance":5.192335910281548,"distance_score":0.22030065048037717,"overall_score":0.18449153215874511,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204747531363051,"value_score":0.5939457760826873}},"metrics":{"distance":1.7099098629719598,"distance_score":0.3690159638384796,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186816714723967,"value_score":0.6307881401514926},"parent_id":"706d13f2-4663-46f6-93b6-78fcf043b2db","timestamp":1747684147.5321305},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.999  # Use a slightly slower cooling rate initially\n    min_temperature = 1e-4  # Allow for a lower minimum temperature for finer search\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        perturbation_scale = max(0.1 * np.exp(-_ / 100) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Enhanced restart mechanism\n        if _ > 0 and _ % adaptive_cooling_threshold == 0:\n            if best_value >= current_value:\n                if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                    # Restart with a focus on unexplored regions\n                    current_x = best_x + np.random.uniform(-1, 1)\n                    current_y = best_y + np.random.uniform(-1, 1)\n                    current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"ce21b5d0-3f22-435a-8b44-e20416b9d464","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 4 lines\nChange 2: Replace perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01) with 2 lines\nChange 3: Replace 7 lines with 8 lines","parent_metrics":{"combined_score":0.3349001626270999,"distance":0.4841698181420444,"distance_score":0.1679899341660393,"overall_score":0.14698003252542,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.1066303074044817,"value_score":0.30750530396214687}},"metrics":{"combined_score":0.34214512427689625,"distance":4.743031487484652,"distance_score":0.20122546018725854,"overall_score":0.1484290248553793,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.634261755501169,"value_score":0.30296247703453116},"parent_id":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","timestamp":1747683731.1503065},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x, best_y, best_value = None, None, float('inf')\n    n_starts = 10  # Increase the number of random restarts to improve exploration\n\n    for _ in range(n_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.99  # Slightly slower cooling to allow longer exploration\n\n        for i in range(iterations):\n            # Adaptive perturbation size based on temperature\n            # Include a momentum term to guide the search\n            momentum = 0.9\n            perturbation_size = max(0.1, temperature / 2.0)\n            new_x = current_x + momentum * (new_x - current_x) + np.random.uniform(-perturbation_size, perturbation_size)\n            new_y = current_y + momentum * (new_y - current_y) + np.random.uniform(-perturbation_size, perturbation_size)\n            new_x = current_x + np.random.uniform(-perturbation_size, perturbation_size)\n            new_y = current_y + np.random.uniform(-perturbation_size, perturbation_size)\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            # Accept the new solution\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best solution found\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Dynamic cooling schedule\n            # Adjust the cooling rate dynamically based on the iteration\n            temperature *= cooling_rate * np.exp(-0.001 * i)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"0092420a-cafb-4d70-b3f1-280521919b4e","island":1,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 5  # Number of random restarts' to 'n_starts = 10  # Increase the number of random restarts to improve exploration'\nChange 2: 'cooling_rate = 0.995' to 'cooling_rate = 0.99  # Slightly slower cooling to allow longer exploration'\nChange 3: Replace perturbation_size = max(0.1, temperature / 2.0) with 5 lines\nChange 4: Replace temperature *= cooling_rate * (1 - (i / iterations)) with 2 lines","parent_metrics":{"combined_score":0.5224576607937255,"distance":5.192335910281548,"distance_score":0.22030065048037717,"overall_score":0.18449153215874511,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204747531363051,"value_score":0.5939457760826873}},"metrics":{"error":0.0},"parent_id":"706d13f2-4663-46f6-93b6-78fcf043b2db","timestamp":1747684708.1567667},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x, best_y, best_value = None, None, float('inf')\n    n_starts = 15  # Increase number of random restarts\n\n    for _ in range(n_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.999  # More gradual cooling\n\n        for i in range(iterations):\n            # Adaptive perturbation size based on temperature\n            # Adapt perturbation size based on the current iteration\n            perturbation_size = max(0.1, temperature * (1 - (i / iterations)))\n            new_x = current_x + np.random.uniform(-perturbation_size, perturbation_size)\n            new_y = current_y + np.random.uniform(-perturbation_size, perturbation_size)\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            # Accept the new solution\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best solution found\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Dynamic cooling schedule\n            temperature *= cooling_rate * (1 - (i / iterations))\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"8e8dfb0a-60fd-4a10-a591-eb5cd6328e09","island":1,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 5  # Number of random restarts' to 'n_starts = 15  # Increase number of random restarts'\nChange 2: 'cooling_rate = 0.995' to 'cooling_rate = 0.999  # More gradual cooling'\nChange 3: Replace perturbation_size = max(0.1, temperature / 2.0) with 2 lines","parent_metrics":{"combined_score":0.5224576607937255,"distance":5.192335910281548,"distance_score":0.22030065048037717,"overall_score":0.18449153215874511,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204747531363051,"value_score":0.5939457760826873}},"metrics":{"distance":1.708042669303264,"distance_score":0.3692704001068358,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186854564275072,"value_score":0.6307896461647974},"parent_id":"706d13f2-4663-46f6-93b6-78fcf043b2db","timestamp":1747684095.7992573},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.999\n    min_temperature = 1e-4  # Allow for a lower minimum temperature for finer search\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]) * temperature, 0.01)\n        gradient_nudge = np.array([np.cos(current_x)*np.cos(current_y) + y*np.cos(current_x*y), \n                                   -np.sin(current_x)*np.sin(current_y) + x*np.cos(current_x*y)])\n        nudge_factor = 0.01 * temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale) + nudge_factor * gradient_nudge[0]\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale) + nudge_factor * gradient_nudge[1]\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Random restart mechanism\n        if _ > 0 and _ % adaptive_cooling_threshold == 0 and current_value > best_value * 1.01:\n            if np.random.rand() < 0.3 + 0.7 * (temperature / 1.0):  # Adaptive restart chance\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        # Dynamically adjust the cooling rate\n        acceptance_rate = min(1.0, np.exp((current_value - new_value) / temperature))\n        cooling_rate = initial_cooling_rate * (0.5 + 0.5 * acceptance_rate)\n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"02877e86-5f0d-40dd-8f4f-355db54fe9ef","island":1,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)' to 'perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]) * temperature, 0.01)'\nChange 2: Replace 2 lines with 2 lines\nChange 3: Replace cooling_rate = initial_cooling_rate * (0.5 + 0.5 * np.cos(np.pi * _ / iterations)) with 2 lines\nChange 4: Replace 2 lines with 5 lines","parent_metrics":{"combined_score":0.47993143926861664,"distance":5.1890139004496065,"distance_score":0.2764172543253523,"overall_score":0.49598628785372334,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204993892200068,"value_score":0.4950104382850183}},"metrics":{"error":0.0},"parent_id":"d819021f-e261-4988-80e6-fa7c521f68e1","timestamp":1747684589.0551121},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.99  # Start with a moderately fast cooling rate\n    cooling_rate_increase = 0.0005  # Gradually increase the cooling rate to slow down cooling over time\n    min_temperature = 1e-6  # Even lower minimum temperature for finer search\n    stagnation_limit = 50  # Start with a more frequent check\n    improvement_threshold = 0.01  # Threshold to determine significant improvement\n    no_improvement_counter = 0  # Counter for iterations without significant improvement\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.05 * temperature, (0.1 + 0.9 * (temperature / (temperature + 1))) * distance_to_best)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Monitor improvement\n        if new_value < best_value - improvement_threshold:\n            no_improvement_counter = 0\n        else:\n            no_improvement_counter += 1\n\n        # Adjust cooling rate based on stagnation\n        if no_improvement_counter > stagnation_limit:\n            # Random restart and adjust cooling rate\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            cooling_rate = max(cooling_rate - cooling_rate_increase, 0.98)  # Ensure cooling rate doesn't drop too low\n            no_improvement_counter = 0\n\n        # Cool down the temperature\n        temperature = max(temperature * cooling_rate, min_temperature)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"641aba0c-77d2-4fb6-9046-59378e35da7e","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: Replace stagnation_limit = 100  # More frequent checks for stagnation with 3 lines\nChange 3: 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1)' to 'perturbation_scale = max(0.05 * temperature, (0.1 + 0.9 * (temperature / (temperature + 1))) * distance_to_best)'\nChange 4: Replace 8 lines with 17 lines","parent_metrics":{"combined_score":0.464591807419669,"distance":4.616838806467545,"distance_score":0.22352815010716592,"overall_score":0.1729183614839338,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8927860597767923,"value_score":0.4958889373125321}},"metrics":{"distance":1.3645326929130552,"distance_score":0.42291654625761194,"overall_score":0.5,"runs_successfully":1.0,"value":-1.3173843590164134,"value_score":0.5597174775932608},"parent_id":"7e837bb2-f97e-47b8-98cd-82d28c4fe891","timestamp":1747684201.7547987},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995 + 0.002 * (1 - it / iterations)  # Adaptive cooling\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.1  # Larger step for more aggressive local search\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"8dc8fd18-8f8a-4737-b429-761dae9faae4","island":1,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.4 * temperature * (1 - it / iterations), 0.02)  # Dynamic scaling'\nChange 2: 'cooling_rate = 0.995  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.995 + 0.002 * (1 - it / iterations)  # Adaptive cooling'\nChange 3: 'step = 0.05' to 'step = 0.1  # Larger step for more aggressive local search'","parent_metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014}},"metrics":{"error":0.0},"parent_id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","timestamp":1747683514.8932924},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.98  # Faster cooling to allow better convergence\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = 0.1 * temperature\n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        \n        # Ensure new_x and new_y remain within bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        # Trigger restart if no improvement in last 200 iterations\n        if _ > 0 and _ % 200 == 0 and best_value >= current_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"ff2a1869-014d-4edc-9748-843d38f941eb","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 4 lines\nChange 2: Replace perturbation_scale = 0.1 * temperature with 2 lines\nChange 3: Replace 4 lines with 5 lines","parent_metrics":{"combined_score":0.35371181446008193,"distance":5.481650992896429,"distance_score":0.1794633008683563,"overall_score":0.15074236289201642,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8806981423956454,"value_score":0.33312137366595845}},"metrics":{"combined_score":0.3325511939492621,"distance":4.0337738327377055,"distance_score":0.17765471232432553,"overall_score":0.14651023878985242,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.25310585514464745,"value_score":0.2987579670866074},"parent_id":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","timestamp":1747684228.4432309},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start simulated annealing and basin hopping.\n    Focuses on exploration and robust escape from local minima.\n    \"\"\"\n    def random_point():\n        return np.random.uniform(bounds[0], bounds[1]), np.random.uniform(bounds[0], bounds[1])\n\n    def clipped(x):\n        return np.clip(x, bounds[0], bounds[1])\n\n    def local_minimize(x0, y0, steps=40, lr=0.02):\n        # Simple gradient descent for local refinement\n        x, y = x0, y0\n        for _ in range(steps):\n            grad_x = np.cos(x) * np.cos(y) + y * np.cos(x * y) + x/10\n            grad_y = -np.sin(x) * np.sin(y) + x * np.cos(x * y) + y/10\n            x = clipped(x - lr * grad_x)\n            y = clipped(y - lr * grad_y)\n        return x, y, evaluate_function(x, y)\n\n    n_starts = 8\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Simulated annealing per start\n        current_x, current_y = random_point()\n        current_value = evaluate_function(current_x, current_y)\n        temperature = 3.0\n        cooling_rate = 0.98\n        min_temperature = 1e-4\n        for it in range(iterations // n_starts):\n            perturbation_scale = max(0.25 * temperature, 0.05)\n            new_x = clipped(current_x + np.random.normal(0, perturbation_scale))\n            new_y = clipped(current_y + np.random.normal(0, perturbation_scale))\n            new_value = evaluate_function(new_x, new_y)\n            if new_value < current_value or np.exp((current_value - new_value) / temperature) > np.random.rand():\n                current_x, current_y, current_value = new_x, new_y, new_value\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Basin hopping: after annealing, perform local descent\n        local_x, local_y, local_val = local_minimize(current_x, current_y)\n        if local_val < best_value:\n            best_x, best_y, best_value = local_x, local_y, local_val\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"f027dd64-4f56-41d8-bb01-4bb6c7065de7","island":1,"language":"python","metadata":{"changes":"Change 1: Replace def local_minimize(x0, y0, steps=40, lr=0.02): with 12 lines\nChange 2: Replace 2 lines with 2 lines\nChange 3: Replace 2 lines with 2 lines","parent_metrics":{"distance":1.7085977494900697,"distance_score":0.3691947245353296,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186743726058185,"value_score":0.6307852359919973}},"metrics":{"distance":1.8307147542726059,"distance_score":0.35326766799467396,"overall_score":0.5,"runs_successfully":1.0,"value":-1.491531269492436,"value_score":0.6201670649980453},"parent_id":"6faffe31-1302-4428-b4dc-abfa216f23b3","timestamp":1747683770.5722716},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.999  # Slower cooling to allow for more exploration initially\n    # Adaptive cooling rate initialized\n    acceptance_rate = 0.0\n    min_temperature = 1e-6  # Even lower minimum temperature for finer search\n    stagnation_limit = 100  # More frequent checks for stagnation\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        # Adaptive perturbation scale based on temperature and acceptance rate\n        perturbation_scale = max(0.1 * temperature, distance_to_best * (0.5 + acceptance_rate))\n        \n        # Simple gradient approximation for directionality\n        grad_x = (evaluate_function(current_x + 0.01, current_y) - current_value) / 0.01\n        grad_y = (evaluate_function(current_x, current_y + 0.01) - current_value) / 0.01\n        new_x = current_x - grad_x * perturbation_scale + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y - grad_y * perturbation_scale + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a more frequent restart mechanism if no improvement is found\n        # Monitor acceptance rate\n        acceptance_rate = 0.9 * acceptance_rate + 0.1 * (1 if accept else 0)\n        \n        # More sophisticated stagnation detection and restart\n        if _ > 0 and _ % stagnation_limit == 0 and current_value >= best_value:\n            # Perform a random restart with adaptive cooling\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            cooling_rate *= 0.95  # Slightly decrease cooling rate to encourage exploration\n        \n        # Adjust cooling rate based on acceptance\n        if acceptance_rate < 0.1:\n            cooling_rate = max(initial_cooling_rate * 0.95, 0.8)\n        elif acceptance_rate > 0.3:\n            cooling_rate = min(initial_cooling_rate * 1.05, 0.999)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"078605d0-6f90-498d-878f-6de7a4ce0099","island":1,"language":"python","metadata":{"changes":"Change 1: Replace cooling_rate = initial_cooling_rate with 2 lines\nChange 2: Replace perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1) with 8 lines\nChange 3: Replace 2 lines with 6 lines\nChange 4: Replace temperature = max(temperature * cooling_rate, min_temperature) with 7 lines","parent_metrics":{"combined_score":0.464591807419669,"distance":4.616838806467545,"distance_score":0.22352815010716592,"overall_score":0.1729183614839338,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8927860597767923,"value_score":0.4958889373125321}},"metrics":{"error":0.0},"parent_id":"7e837bb2-f97e-47b8-98cd-82d28c4fe891","timestamp":1747684327.4121463},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.99  # Adjusted initial cooling rate for faster convergence\n    min_temperature = 1e-4  # Lower minimum temperature to allow finer search near potential minima\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.2 * temperature, 0.01)  # Increased initial perturbation scale for better exploration\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Adaptive cooling rate adjustment based on lack of improvement\n        if _ % 50 == 0 and current_value >= best_value:\n            cooling_rate *= 0.95  # Decrease cooling rate to enhance exploration\n\n        # Enhanced restart mechanism to escape local minima\n        if _ % 200 == 0 and current_value >= best_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"f028dcf8-1187-4d9e-abbc-13af55ad1ac3","island":1,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.995  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.99  # Adjusted initial cooling rate for faster convergence'\nChange 2: 'min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping' to 'min_temperature = 1e-4  # Lower minimum temperature to allow finer search near potential minima'\nChange 3: 'perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature' to 'perturbation_scale = max(0.2 * temperature, 0.01)  # Increased initial perturbation scale for better exploration'\nChange 4: Replace 2 lines with 6 lines","parent_metrics":{"combined_score":0.4295829772045145,"distance":5.38642309351845,"distance_score":0.25910925725707623,"overall_score":0.16591659544090293,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.3330121050816872,"value_score":0.41975033337898615}},"metrics":{"combined_score":0.42344418797298744,"distance":2.310317787008159,"distance_score":0.2109735806742769,"overall_score":0.4846888375945975,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1540861810814285,"value_score":0.4335868562845074},"parent_id":"afac1ee8-bea7-496c-b102-c197942c8bfa","timestamp":1747684817.1098888},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.995  # Start with a slightly slower cooling for more exploration\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature * (1 + np.random.rand()), 0.01)  # Add randomness to perturbation scale\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Adaptive restart mechanism with stagnation detection\n        if _ % 100 == 0:\n            if current_value >= best_value:\n                restart_probability = (temperature / (temperature + 1)) * 0.5\n                if np.random.rand() < restart_probability:\n                    current_x = np.random.uniform(bounds[0], bounds[1])\n                    current_y = np.random.uniform(bounds[0], bounds[1])\n                    current_value = evaluate_function(current_x, current_y)\n                # Adjust the cooling rate adaptively based on progress\n                cooling_rate = initial_cooling_rate * (0.9 + 0.1 * (best_value / (abs(best_value) + 1)))\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"8a86605a-8bc7-4c6c-a0a3-f4fdee4883bb","island":1,"language":"python","metadata":{"changes":"Change 1: Replace cooling_rate = 0.995  # Slightly slower cooling for more exploration with 2 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature' to 'perturbation_scale = max(0.1 * temperature * (1 + np.random.rand()), 0.01)  # Add randomness to perturbation scale'\nChange 3: Replace 5 lines with 10 lines","parent_metrics":{"combined_score":0.4195085898276592,"distance":3.8937782311748976,"distance_score":0.21685621318163473,"overall_score":0.16390171796553188,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.1484761802416486,"value_score":0.4240862097886148}},"metrics":{"combined_score":0.4468310157834882,"distance":6.071918133930994,"distance_score":0.20175500454188094,"overall_score":0.48936620315669765,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9282770999302274,"value_score":0.47717419070153994},"parent_id":"e86a55b6-c88c-4f87-bea5-fa91b418d3e4","timestamp":1747684367.810226},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_temperature = 1.0\n    cooling_rate = 0.998  # Adjust the cooling rate for a more aggressive initial search\n    min_temperature = 1e-6  # Allow for even lower minimum temperature for finer search\n    adaptive_cooling_factor = 0.95  # Introduce dynamic adjustment factor for cooling rate\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Enhanced perturbation mechanism with dynamic scaling\n        perturbation_scale = max(0.1 * (1 + 0.5 * (best_value - current_value) / abs(best_value + 1e-6)), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Dynamic cooling schedule adjustment based on progress\n        if _ % 100 == 0:\n            if best_value < current_value:\n                cooling_rate *= adaptive_cooling_factor\n        if _ > 0 and _ % adaptive_cooling_threshold == 0:\n            if best_value >= current_value:\n                if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                    # Restart with a focus on unexplored regions\n                    current_x = best_x + np.random.uniform(-1, 1)\n                    current_y = best_y + np.random.uniform(-1, 1)\n                    current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"600d84ab-ea0d-418b-8b02-4a00e6378024","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 4 lines\nChange 2: Replace 3 lines with 2 lines\nChange 3: Replace 2 lines with 4 lines","parent_metrics":{"combined_score":0.34214512427689625,"distance":4.743031487484652,"distance_score":0.20122546018725854,"overall_score":0.1484290248553793,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.634261755501169,"value_score":0.30296247703453116}},"metrics":{"distance":1.7061174685288694,"distance_score":0.3695331084587512,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186772524988208,"value_score":0.6307863818747458},"parent_id":"ce21b5d0-3f22-435a-8b44-e20416b9d464","timestamp":1747684134.1555688},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.999\n    min_temperature = 1e-4  # Allow for a lower minimum temperature for finer search\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]) * temperature, 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Random restart mechanism\n        if _ > 0 and _ % adaptive_cooling_threshold == 0:\n            # Enhance the random restart mechanism\n            new_x = np.random.uniform(bounds[0], bounds[1])\n            new_y = np.random.uniform(bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            if new_value < best_value:  # Only restart if we find a promising new point\n                current_x, current_y, current_value = new_x, new_y, new_value\n        \n        # Dynamically adjust the cooling rate\n        # Adaptive cooling based on lack of improvement\n        if current_value == best_value:  # No improvement found\n            cooling_rate = initial_cooling_rate * 0.99  # Cool faster if stuck\n        else:\n            cooling_rate = initial_cooling_rate * (0.5 + 0.5 * np.cos(np.pi * _ / iterations))\n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"20b0f31a-37ca-45f0-a870-ca164644f5d9","island":1,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)' to 'perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]) * temperature, 0.01)'\nChange 2: Replace 5 lines with 7 lines\nChange 3: Replace cooling_rate = initial_cooling_rate * (0.5 + 0.5 * np.cos(np.pi * _ / iterations)) with 5 lines","parent_metrics":{"combined_score":0.47993143926861664,"distance":5.1890139004496065,"distance_score":0.2764172543253523,"overall_score":0.49598628785372334,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204993892200068,"value_score":0.4950104382850183}},"metrics":{"combined_score":0.4139792347490776,"distance":4.323101623843643,"distance_score":0.20703423841625335,"overall_score":0.16279584694981553,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.07343023075030597,"value_score":0.4197816053736693},"parent_id":"d819021f-e261-4988-80e6-fa7c521f68e1","timestamp":1747684273.820815},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.999\n    min_temperature = 1e-4  # Allow for a lower minimum temperature for finer search\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        # Adaptive perturbation based on temperature and recent performance\n        perturbation_scale = max(0.1 * temperature, 0.01)\n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Random restart mechanism\n        # Strategic restart based on stagnation\n        if _ > 0 and _ % adaptive_cooling_threshold == 0 and best_value - current_value < 1e-5:\n            if np.random.rand() < 0.3:  # 30% chance to restart if not much improvement\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        # Dynamically adjust the cooling rate\n        # Exponential decay for cooling\n        cooling_rate = 0.99  # More aggressive cooling\n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"c8d7f975-d28d-4d6d-9e7a-581a88a1ad10","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 4 lines\nChange 2: Replace cooling_rate = initial_cooling_rate * (0.5 + 0.5 * np.cos(np.pi * _ / iterations)) with 2 lines\nChange 3: Replace 2 lines with 3 lines","parent_metrics":{"combined_score":0.47993143926861664,"distance":5.1890139004496065,"distance_score":0.2764172543253523,"overall_score":0.49598628785372334,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204993892200068,"value_score":0.4950104382850183}},"metrics":{"combined_score":0.4172396264418222,"distance":5.098756851702309,"distance_score":0.19629328792569578,"overall_score":0.16344792528836447,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.3292443516039463,"value_score":0.4305860667735226},"parent_id":"d819021f-e261-4988-80e6-fa7c521f68e1","timestamp":1747684252.9531767},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.999\n    min_temperature = 1e-4  # Allow for a lower minimum temperature for finer search\n    adaptive_cooling_threshold = 200  # Introduce a threshold for adaptive cooling\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        # Dynamic perturbation scale based on distance to the best-known solution\n        perturbation_scale = max(0.1 * (1 - _ / iterations) * np.linalg.norm([current_x - best_x, current_y - best_y]), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Random restart mechanism\n        if _ > 0 and _ % adaptive_cooling_threshold == 0:\n            if np.random.rand() < 0.5:  # 50% chance to restart\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        # Dynamically adjust the cooling rate\n        cooling_rate = initial_cooling_rate * (0.5 + 0.5 * np.cos(np.pi * _ / iterations))\n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"5c7f766a-c055-4cc1-8616-c19b894d2f74","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 4 lines with 4 lines\nChange 2: Replace 3 lines with 3 lines\nChange 3: Replace 5 lines with 5 lines","parent_metrics":{"combined_score":0.47993143926861664,"distance":5.1890139004496065,"distance_score":0.2764172543253523,"overall_score":0.49598628785372334,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204993892200068,"value_score":0.4950104382850183}},"metrics":{"distance":1.7617726040328416,"distance_score":0.3620862914418672,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5040937099471936,"value_score":0.6250366075921822},"parent_id":"d819021f-e261-4988-80e6-fa7c521f68e1","timestamp":1747684284.7298274},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 12  # More random restarts for better global search\n    best_overall = None\n    best_value_overall = np.inf\n\n    for start in range(n_starts):\n        # Random initialization for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Annealing parameters for this run\n        temperature = 2.5  # Slightly higher to encourage more exploration\n        cooling_rate = 0.992  # Slower cooling for better exploration\n        local_iter = iterations // n_starts\n\n        for _ in range(local_iter):\n            # Adaptive step size based on temperature\n            step_size = 0.15 * temperature\n            # Propose a new candidate (clip to bounds)\n            new_x = np.clip(current_x + np.random.uniform(-step_size, step_size), bounds[0], bounds[1])\n            new_y = np.clip(current_y + np.random.uniform(-step_size, step_size), bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                delta = new_value - current_value\n                accept = np.exp(-delta / max(temperature, 1e-8)) > np.random.rand()\n\n            # Accept or reject\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best for this run\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Cool down\n            temperature *= cooling_rate\n\n        # After annealing, perform a brief local search (hill climbing)\n        for _ in range(10):\n            grad_x = (evaluate_function(best_x + 1e-4, best_y) - evaluate_function(best_x - 1e-4, best_y)) / 2e-4\n            grad_y = (evaluate_function(best_x, best_y + 1e-4) - evaluate_function(best_x, best_y - 1e-4)) / 2e-4\n            # Small step in negative gradient direction\n            step = 0.05\n            best_x = np.clip(best_x - step * grad_x, bounds[0], bounds[1])\n            best_y = np.clip(best_y - step * grad_y, bounds[0], bounds[1])\n            best_value = evaluate_function(best_x, best_y)\n\n        # Track the best overall result\n        if best_value < best_value_overall:\n            best_overall = (best_x, best_y, best_value)\n            best_value_overall = best_value\n\n    return best_overall\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":2,"id":"4d5f7a30-9954-49e8-9819-b2415aa9599a","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 44 lines with 63 lines","parent_metrics":{"combined_score":0.4340846850557817,"distance":6.116510764280398,"distance_score":0.23743554909359196,"overall_score":0.48681693701115636,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6790898014054345,"value_score":0.4380900338795069}},"metrics":{"distance":1.6447942907207354,"distance_score":0.3781012396724015,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5065319973050537,"value_score":0.6259906291161944},"parent_id":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","timestamp":1747683437.2959266},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        if _ % 100 == 0 and current_value >= best_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"afac1ee8-bea7-496c-b102-c197942c8bfa","island":1,"language":"python","metadata":{"changes":"Change 1: Replace cooling_rate = 0.995  # Slightly slower cooling for more exploration with 3 lines\nChange 2: Replace 4 lines with 5 lines\nChange 3: Replace perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature with 2 lines","parent_metrics":{"combined_score":0.4258850392234609,"distance":3.5144723081215075,"distance_score":0.23192590491212237,"overall_score":0.4851770078446922,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.6030190517040648,"value_score":0.42717877958304035}},"metrics":{"combined_score":0.4295829772045145,"distance":5.38642309351845,"distance_score":0.25910925725707623,"overall_score":0.16591659544090293,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.3330121050816872,"value_score":0.41975033337898615},"parent_id":"f533ce2b-cb5a-43ff-9fb0-2b7eafb531bd","timestamp":1747684390.405368},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 5.0  # Increase initial temperature for better exploration\n    cooling_rate = 0.995  # Slower cooling rate for more gradual temperature decrease\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive step size based on current temperature\n        step_size = temperature / 10\n        new_x = current_x + np.random.uniform(-step_size, step_size)\n        new_y = current_y + np.random.uniform(-step_size, step_size)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        # Adjust acceptance criteria to gradually favor better solutions\n        delta = new_value - current_value\n        accept = np.exp(-delta / max(temperature, 1e-8)) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        temperature *= cooling_rate\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":2,"id":"9de857f8-a6a5-4820-9c89-74ccd7d43890","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: Replace 2 lines with 4 lines\nChange 3: Replace 4 lines with 3 lines","parent_metrics":{"combined_score":0.4340846850557817,"distance":6.116510764280398,"distance_score":0.23743554909359196,"overall_score":0.48681693701115636,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6790898014054345,"value_score":0.4380900338795069}},"metrics":{"combined_score":0.3982712804394811,"distance":5.020353751430206,"distance_score":0.18328551336605725,"overall_score":0.15965425608789624,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4222781661106263,"value_score":0.40547604404944},"parent_id":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","timestamp":1747684760.7750347},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.95  # Adjusted for more gradual cooling\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-6  # Lower minimum temperature for finer search\n    stagnation_limit = 100  # More frequent stagnation checks for quicker response\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.1 * temperature, distance_to_best * 0.2 * np.log(iterations / (_ + 1)))\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a more dynamic restart mechanism\n        if _ % stagnation_limit == 0:\n            # If stagnation detected, restart with a broader exploration\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            temperature = 1.0  # Reheat the system\n        else:\n            # Introduce adaptive perturbations to escape local minima\n            current_x += np.random.uniform(-0.2, 0.2) * (temperature / initial_cooling_rate)\n            current_y += np.random.uniform(-0.2, 0.2) * (temperature / initial_cooling_rate)\n            current_value = evaluate_function(current_x, current_y)\n\n        # Cool down the temperature based on progress\n        if _ % 10 == 0 and current_value < best_value:\n            cooling_rate *= 1.1  # Slightly increase cooling rate to consolidate gains\n        temperature = max(temperature * cooling_rate, min_temperature)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"8715ee97-7152-488f-b085-9a0a7731120d","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 4 lines with 4 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1 * (temperature / initial_cooling_rate))' to 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.2 * np.log(iterations / (_ + 1)))'\nChange 3: Replace 16 lines with 17 lines","parent_metrics":{"combined_score":0.5227008996722041,"distance":2.8909901674767875,"distance_score":0.24153648181166762,"overall_score":0.5045401799344409,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1598740927883568,"value_score":0.5837332585478398}},"metrics":{"distance":1.646692597512056,"distance_score":0.37783005134031056,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5097189569858607,"value_score":0.6272419811938585},"parent_id":"1576f604-4dd5-4b3f-88d8-29fff3a87f55","timestamp":1747684448.345473},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Global minimum search using hybrid Differential Evolution + Simulated Annealing.\n    \"\"\"\n    # Differential Evolution parameters\n    pop_size = 15\n    F = 0.7\n    CR = 0.9\n    dim = 2\n    np.random.seed(None)\n    pop = np.random.uniform(bounds[0], bounds[1], (pop_size, dim))\n    fitness = np.array([evaluate_function(ind[0], ind[1]) for ind in pop])\n    best_idx = np.argmin(fitness)\n    best_x, best_y, best_value = pop[best_idx,0], pop[best_idx,1], fitness[best_idx]\n\n    for gen in range(int(iterations*0.6)):\n        for i in range(pop_size):\n            idxs = [idx for idx in range(pop_size) if idx != i]\n            a, b, c = pop[np.random.choice(idxs, 3, replace=False)]\n            mutant = np.clip(a + F * (b - c), bounds[0], bounds[1])\n            cross_points = np.random.rand(dim) < CR\n            if not np.any(cross_points):\n                cross_points[np.random.randint(0, dim)] = True\n            trial = np.where(cross_points, mutant, pop[i])\n            trial_value = evaluate_function(trial[0], trial[1])\n            if trial_value < fitness[i]:\n                pop[i] = trial\n                fitness[i] = trial_value\n                if trial_value < best_value:\n                    best_x, best_y, best_value = trial[0], trial[1], trial_value\n\n    # Simulated Annealing local refinement around best found\n    current_x, current_y = best_x, best_y\n    current_value = best_value\n    temperature = 1.0\n    cooling_rate = 0.993\n    for i in range(int(iterations*0.4)):\n        perturbation_size = max(0.05, temperature / 4.0)\n        new_x = np.clip(current_x + np.random.uniform(-perturbation_size, perturbation_size), bounds[0], bounds[1])\n        new_y = np.clip(current_y + np.random.uniform(-perturbation_size, perturbation_size), bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n        if new_value < current_value:\n            current_x, current_y, current_value = new_x, new_y, new_value\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n        else:\n            if np.exp((current_value - new_value) / temperature) > np.random.rand():\n                current_x, current_y, current_value = new_x, new_y, new_value\n        temperature *= cooling_rate\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"eb97324d-0ef0-4464-9922-a74cb1211ce4","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 48 lines with 51 lines","parent_metrics":{"combined_score":0.5224576607937255,"distance":5.192335910281548,"distance_score":0.22030065048037717,"overall_score":0.18449153215874511,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204747531363051,"value_score":0.5939457760826873}},"metrics":{"distance":1.708423153547417,"distance_score":0.3692185243248374,"overall_score":0.5,"runs_successfully":1.0,"value":-1.518685840848579,"value_score":0.6307897991242789},"parent_id":"706d13f2-4663-46f6-93b6-78fcf043b2db","timestamp":1747683972.4791572},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=2000, bounds=(-5, 5), n_restarts=5):\n    \"\"\"\n    Enhanced global minimization using multi-start and adaptive simulated annealing.\n\n    Args:\n        iterations: Number of iterations per run\n        bounds: Bounds for the search space (min, max)\n        n_restarts: Number of independent restarts\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    def clip(val):\n        return np.clip(val, bounds[0], bounds[1])\n\n    overall_best_x, overall_best_y, overall_best_value = None, None, float('inf')\n    for restart in range(n_restarts):\n        # Initialize with a random point\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        best_x, best_y, best_value = current_x, current_y, current_value\n\n        temperature = 1.5\n        cooling_rate = 0.993  # Slower cooling to enhance exploration\n        min_temperature = 1e-4\n\n        no_improve_counter = 0\n        for i in range(iterations):\n            # Adaptive perturbation: larger jumps at high temperature, smaller at low\n            perturb_scale = max(0.25 * temperature, 0.01)\n            # Occasionally make a large jump to escape local minima\n            if np.random.rand() < 0.01:\n                new_x = np.random.uniform(bounds[0], bounds[1])\n                new_y = np.random.uniform(bounds[0], bounds[1])\n            else:\n                new_x = clip(current_x + np.random.normal(0, perturb_scale))\n                new_y = clip(current_y + np.random.normal(0, perturb_scale))\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criterion\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_counter = 0\n            else:\n                no_improve_counter += 1\n\n            # Occasional random restart if stuck\n            if no_improve_counter > 300:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_counter = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        if best_value < overall_best_value:\n            overall_best_x, overall_best_y, overall_best_value = best_x, best_y, best_value\n\n    return overall_best_x, overall_best_y, overall_best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"629c9627-552b-4876-b571-987c8c182a14","island":1,"language":"python","metadata":{"changes":"Change 1: Replace 52 lines with 68 lines","parent_metrics":{"combined_score":0.4258850392234609,"distance":3.5144723081215075,"distance_score":0.23192590491212237,"overall_score":0.4851770078446922,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.6030190517040648,"value_score":0.42717877958304035}},"metrics":{"distance":1.7077588241812698,"distance_score":0.3693091094633823,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186807939716778,"value_score":0.6307877909996976},"parent_id":"f533ce2b-cb5a-43ff-9fb0-2b7eafb531bd","timestamp":1747683917.6204822},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        if _ % 100 == 0 and current_value >= best_value and np.random.rand() < 0.5:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"e86a55b6-c88c-4f87-bea5-fa91b418d3e4","island":2,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature' to 'perturbation_scale = max(0.1 * temperature * (1 - _ / iterations), 0.01)  # Adjust perturbation over iterations'\nChange 2: 'if _ % 100 == 0 and current_value >= best_value:' to 'if _ % 100 == 0 and current_value >= best_value and np.random.rand() < 0.5:'\nChange 3: 'temperature = max(temperature * cooling_rate, min_temperature)' to 'temperature = max(temperature * cooling_rate**(1 + _ / iterations), min_temperature)'","parent_metrics":{"combined_score":0.41411306444653023,"distance":2.4411503423243888,"distance_score":0.18678802902100744,"overall_score":0.16282261288930605,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8738212402463125,"value_score":0.43012775956704674}},"metrics":{"combined_score":0.4195085898276592,"distance":3.8937782311748976,"distance_score":0.21685621318163473,"overall_score":0.16390171796553188,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.1484761802416486,"value_score":0.4240862097886148},"parent_id":"378c023c-827e-4016-b9de-265020c5e8dd","timestamp":1747684172.6680126},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995  # Slightly slower cooling for more exploration\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = 100  # Increase patience to allow more exploration\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.05 + 0.01 * (temperature / max_temperature)  # Step size adapts with temperature\n                momentum = 0.1  # Introduce momentum\n                grad_x = momentum * grad_x + (1 - momentum) * ((evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4)\n                grad_y = momentum * grad_y + (1 - momentum) * ((evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4)\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate * (1 + 0.1 * (it / iterations)), min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"ff395f9d-67eb-4f2c-9fe3-9c20c126321a","island":2,"language":"python","metadata":{"changes":"Change 1: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.4 * temperature * (1 - it / iterations), 0.01)  # Dynamic scale'\nChange 2: 'patience = 80' to 'patience = 100  # Increase patience to allow more exploration'\nChange 3: Replace step = 0.05 with 4 lines\nChange 4: 'temperature = max(temperature * cooling_rate, min_temperature)' to 'temperature = max(temperature * cooling_rate * (1 + 0.1 * (it / iterations)), min_temperature)'","parent_metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014}},"metrics":{"error":0.0},"parent_id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","timestamp":1747684029.5502849},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 20  # Further increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.5\n        cooling_rate = 0.990  # Slightly slower cooling for more thorough exploration\n        min_temperature = 1e-8  # Even lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.5 * temperature, 0.01)  # More dynamic scale with lower bound\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 10 == 0:  # Even more frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.1 * (temperature / 1.5)  # Adaptive step size based on temperature\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience and temperature > 0.1:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"5c6689f0-8227-4cd8-a461-c58cb10c9645","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 12 lines with 12 lines\nChange 2: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.5 * temperature, 0.01)  # More dynamic scale with lower bound'\nChange 3: 'if it % 20 == 0:  # More frequent local search' to 'if it % 10 == 0:  # Even more frequent local search'\nChange 4: 'step = 0.05' to 'step = 0.1 * (temperature / 1.5)  # Adaptive step size based on temperature'\nChange 5: 'if no_improve_count > patience:' to 'if no_improve_count > patience and temperature > 0.1:'","parent_metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014}},"metrics":{"distance":1.7520402516205702,"distance_score":0.3633667783060726,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5127957119492823,"value_score":0.6284548172158559},"parent_id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","timestamp":1747683804.8591928},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.99  # Slightly higher to allow more initial exploration\n    cooling_rate = initial_cooling_rate\n    min_temperature = 1e-5  # Lower minimum temperature for finer search\n    stagnation_limit = 200  # Iterations before considering stagnation\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Dynamic perturbation scale based on distance from best known point\n        distance_to_best = np.sqrt((current_x - best_x)**2 + (current_y - best_y)**2)\n        perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1 * (temperature / initial_cooling_rate))\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Check for stagnation and adapt cooling rate\n        if current_value >= best_value:\n            if _ % stagnation_limit == 0:\n                # Restart with a broader exploration if stagnation is detected\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                cooling_rate *= 0.95  # Slightly less aggressive cooling on stagnation\n            else:\n                # Introduce small perturbations to escape potential local minima\n                current_x += np.random.uniform(-0.5, 0.5)\n                current_y += np.random.uniform(-0.5, 0.5)\n                current_value = evaluate_function(current_x, current_y)\n        else:\n            cooling_rate = initial_cooling_rate  # Reset cooling rate on improvement\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"1576f604-4dd5-4b3f-88d8-29fff3a87f55","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.05)' to 'perturbation_scale = max(0.1 * temperature, distance_to_best * 0.1 * (temperature / initial_cooling_rate))'\nChange 3: Replace 11 lines with 14 lines","parent_metrics":{"combined_score":0.4486355733848136,"distance":0.8036624705482555,"distance_score":0.22602127933344787,"overall_score":0.16972711467696272,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.29619770166506365,"value_score":0.46804864930796547}},"metrics":{"combined_score":0.5227008996722041,"distance":2.8909901674767875,"distance_score":0.24153648181166762,"overall_score":0.5045401799344409,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1598740927883568,"value_score":0.5837332585478398},"parent_id":"d739b8c2-8dcc-41d6-bf83-eec8e490a417","timestamp":1747684189.0969121},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    initial_cooling_rate = 0.995  # Start with a slower cooling rate\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability and accept new solution\n        delta_value = new_value - current_value\n        if delta_value < 0 or np.exp(-delta_value / temperature) > np.random.rand():\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Dynamic cooling rate adjustment\n        cooling_rate = initial_cooling_rate - (_ / iterations) * 0.5  # Gradually increase cooling rate\n\n        # Restart mechanism with local search\n        if _ % 100 == 0 and current_value >= best_value:\n            # Perform a local search to fine-tune the current best solution\n            local_search_result = local_search(current_x, current_y)\n            current_x, current_y, current_value = local_search_result\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef local_search(x, y):\n    \"\"\"Perform a simple local search using a gradient-free method like Nelder-Mead.\"\"\"\n    from scipy.optimize import minimize\n    result = minimize(lambda vars: evaluate_function(vars[0], vars[1]), [x, y], method='Nelder-Mead')\n    return result.x[0], result.x[1], result.fun\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"f57ef594-176b-495f-9c74-729279328664","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 3 lines\nChange 2: Replace 8 lines with 3 lines\nChange 3: Replace 3 lines with 8 lines\nChange 4: Replace def evaluate_function(x, y): with 5 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"error":0.0},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683426.0542731},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A robust global optimization algorithm combining multi-start, simulated annealing, and random restarts.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: run several independent simulated annealing searches\n    n_starts = 5\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n\n        temperature = 2.0\n        cooling_rate = 0.995\n        min_temperature = 1e-4\n\n        no_improve_count = 0\n        last_improve_iter = 0\n        max_no_improve = iterations // 8  # Trigger restart if stuck\n\n        for i in range(iterations // n_starts):\n            # Generate a new candidate point by adding a scaled perturbation\n            perturbation_scale = max(0.5 * temperature, 0.01)\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n            # Ensure inside bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            if current_value < local_best_value:\n                local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n                no_improve_count = 0\n                last_improve_iter = i\n            else:\n                no_improve_count += 1\n\n            # Random restart if no improvement for several iterations\n            if no_improve_count > max_no_improve:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Update best found across all starts\n        if local_best_value < best_value:\n            best_x, best_y, best_value = local_best_x, local_best_y, local_best_value\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"45e549b7-f72c-4e8d-8412-19a69435482e","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 52 lines with 69 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"distance":1.7191620906425458,"distance_score":0.36776034920511014,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5034596772479558,"value_score":0.6247890076774529},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683502.3867292},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.999  # Even slower cooling for more exploration\n        min_temperature = 1e-8  # Even lower minimum temperature for finer convergence\n\n        patience = 80\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.5 * temperature, 0.01)  # Increased scale for more exploration\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.1  # Larger step size for more aggressive local search\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                # Systematic exploration across the domain\n                for _ in range(5):  # Try five new random positions\n                    temp_x = np.random.uniform(bounds[0], bounds[1])\n                    temp_y = np.random.uniform(bounds[0], bounds[1])\n                    temp_value = evaluate_function(temp_x, temp_y)\n                    if temp_value < current_value:\n                        current_x, current_y, current_value = temp_x, temp_y, temp_value\n                        break\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"70276b82-e4ed-4d78-89f2-e76969f89438","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.5 * temperature, 0.01)  # Increased scale for more exploration'\nChange 3: 'step = 0.05' to 'step = 0.1  # Larger step size for more aggressive local search'\nChange 4: Replace 4 lines with 9 lines","parent_metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014}},"metrics":{"distance":1.7255297087131702,"distance_score":0.3669011556920946,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5176602317293262,"value_score":0.630381977431062},"parent_id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","timestamp":1747684120.6977837},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization: multi-start simulated annealing with periodic global random restarts and adaptive step sizes.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    n_starts = 5  # Number of random restarts at the top level\n    best_x, best_y, best_value = None, None, float('inf')\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n        temperature = 2.0  # Higher initial temperature for more exploration\n        cooling_rate = 0.992  # Slower cooling for more exploration\n        min_temperature = 1e-4\n        plateau_count = 0\n        plateau_limit = max(20, iterations//20)\n        for i in range(iterations//n_starts):\n            # Adaptive perturbation: larger steps at high temperature, smaller at low\n            perturbation_scale = max(0.25 * temperature, 0.01)\n            new_x = np.clip(current_x + np.random.normal(0, perturbation_scale), bounds[0], bounds[1])\n            new_y = np.clip(current_y + np.random.normal(0, perturbation_scale), bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            # Metropolis criterion\n            if new_value < current_value:\n                accept = True\n            else:\n                delta = new_value - current_value\n                accept = np.exp(-delta / temperature) > np.random.rand()\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                plateau_count = 0\n            else:\n                plateau_count += 1\n            # Update local best\n            if current_value < local_best_value:\n                local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n            # Adaptive global jump if stuck\n            if plateau_count > plateau_limit:\n                # Large random jump to a new region\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                plateau_count = 0\n            temperature = max(temperature * cooling_rate, min_temperature)\n        # Update overall best\n        if local_best_value < best_value:\n            best_x, best_y, best_value = local_best_x, local_best_y, local_best_value\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"e7cfc40d-11b2-4acb-aaac-2c7bd5401c51","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 52 lines with 56 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"distance":1.669357558197899,"distance_score":0.3746219748376859,"overall_score":0.5,"runs_successfully":1.0,"value":-1.4976860398899163,"value_score":0.6225433040073113},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683851.9200754},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A robust global optimization algorithm combining multi-start, simulated annealing, and random restarts.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: run several independent simulated annealing searches\n    n_starts = 10  # Increased for better exploration\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n\n        temperature = 2.5  # Slightly higher starting temperature\n        cooling_rate = 0.99  # Adjusted for smoother cooling\n        min_temperature = 1e-4\n\n        no_improve_count = 0\n        last_improve_iter = 0\n        max_no_improve = iterations // 8  # Trigger restart if stuck\n\n        for i in range(iterations // n_starts):\n            # Generate a new candidate point by adding a scaled perturbation\n            perturbation_scale = max(0.5 * temperature, 0.05)  # Adjusted minimum scale\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n            # Ensure inside bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            if current_value < local_best_value:\n                local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n                no_improve_count = 0\n                last_improve_iter = i\n            else:\n                no_improve_count += 1\n\n            # Random restart if no improvement for several iterations\n            # Dynamic restart based on improvement rate\n            if no_improve_count > max_no_improve or (i - last_improve_iter) > iterations // (2 * n_starts):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Update best found across all starts\n        if local_best_value < best_value:\n            best_x, best_y, best_value = local_best_x, local_best_y, local_best_value\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"df745310-83ff-4a2f-b5c6-bb524df03055","island":2,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 5' to 'n_starts = 10  # Increased for better exploration'\nChange 2: Replace 2 lines with 2 lines\nChange 3: 'perturbation_scale = max(0.5 * temperature, 0.01)' to 'perturbation_scale = max(0.5 * temperature, 0.05)  # Adjusted minimum scale'\nChange 4: Replace if no_improve_count > max_no_improve: with 2 lines","parent_metrics":{"distance":1.7191620906425458,"distance_score":0.36776034920511014,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5034596772479558,"value_score":0.6247890076774529}},"metrics":{"distance":1.7924826056410745,"distance_score":0.3581042897026133,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5007780014193184,"value_score":0.6237439362017807},"parent_id":"45e549b7-f72c-4e8d-8412-19a69435482e","timestamp":1747683824.4761057},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 12  # More random restarts for better global search\n    best_overall = None\n    best_value_overall = np.inf\n\n    for start in range(n_starts):\n        # Random initialization for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Annealing parameters for this run\n        temperature = 2.5  # Slightly higher to encourage more exploration\n        cooling_rate = 0.992  # Slower cooling for better exploration\n        local_iter = iterations // n_starts\n\n        for _ in range(local_iter):\n            # Adaptive step size based on temperature\n            step_size = 0.15 * temperature\n            # Propose a new candidate (clip to bounds)\n            new_x = np.clip(current_x + np.random.uniform(-step_size, step_size), bounds[0], bounds[1])\n            new_y = np.clip(current_y + np.random.uniform(-step_size, step_size), bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                delta = new_value - current_value\n                accept = np.exp(-delta / max(temperature, 1e-8)) > np.random.rand()\n\n            # Accept or reject\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best for this run\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Cool down\n            temperature *= cooling_rate\n\n        # After annealing, perform a brief local search (hill climbing)\n        for _ in range(10):\n            grad_x = (evaluate_function(best_x + 1e-4, best_y) - evaluate_function(best_x - 1e-4, best_y)) / 2e-4\n            grad_y = (evaluate_function(best_x, best_y + 1e-4) - evaluate_function(best_x, best_y - 1e-4)) / 2e-4\n            # Small step in negative gradient direction\n            step = 0.05\n            best_x = np.clip(best_x - step * grad_x, bounds[0], bounds[1])\n            best_y = np.clip(best_y - step * grad_y, bounds[0], bounds[1])\n            best_value = evaluate_function(best_x, best_y)\n\n        # Track the best overall result\n        if best_value < best_value_overall:\n            best_overall = (best_x, best_y, best_value)\n            best_value_overall = best_value\n\n    return best_overall\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"b9008af3-16d8-464c-b61b-e9d5815b1551","island":2,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 12  # More random restarts for better global search' to 'n_starts = 20  # Increase number of random restarts for broader search'\nChange 2: Replace 2 lines with 2 lines\nChange 3: 'step_size = 0.15 * temperature' to 'step_size = 0.2 * temperature  # Increase step size for broader moves'\nChange 4: Replace 5 lines with 5 lines","parent_metrics":{"distance":1.6447942907207354,"distance_score":0.3781012396724015,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5065319973050537,"value_score":0.6259906291161944}},"metrics":{"distance":1.6769128227779755,"distance_score":0.37356464935688366,"overall_score":0.5,"runs_successfully":1.0,"value":-1.50959634457388,"value_score":0.6271937451954349},"parent_id":"4d5f7a30-9954-49e8-9819-b2415aa9599a","timestamp":1747683586.5373564},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start, adaptive simulated annealing, and occasional large jumps.\n    \"\"\"\n    # Multi-start: sample several random starting points, keep best initial\n    n_starts = 5\n    best_x, best_y, best_value = None, None, np.inf\n    for _ in range(n_starts):\n        tx = np.random.uniform(bounds[0], bounds[1])\n        ty = np.random.uniform(bounds[0], bounds[1])\n        v = evaluate_function(tx, ty)\n        if v < best_value:\n            best_x, best_y, best_value = tx, ty, v\n\n    current_x, current_y, current_value = best_x, best_y, best_value\n    temperature = 2.0\n    cooling_rate = 0.985\n    min_temperature = 1e-3\n\n    no_improve_counter = 0\n    last_best_value = best_value\n\n    for i in range(iterations):\n        # Adaptive perturbation: mix local and global steps\n        if np.random.rand() < 0.85:\n            perturbation_scale = (0.15 + 0.3 * temperature) # local step\n        else:\n            perturbation_scale = np.random.uniform(0.5, 1.5) * (bounds[1] - bounds[0]) # large jump\n        \n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        # Stay in bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Accept according to SA\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / (temperature + 1e-10)) > np.random.rand()\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Track best\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Restart if stuck\n        if abs(last_best_value - best_value) < 1e-6:\n            no_improve_counter += 1\n        else:\n            no_improve_counter = 0\n        last_best_value = best_value\n\n        if no_improve_counter > 150:\n            # Do a global random restart with 20% chance\n            if np.random.rand() < 0.2:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n            no_improve_counter = 0\n\n        temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"e9abc13d-338a-4920-a730-f010769fb437","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 59 lines with 66 lines","parent_metrics":{"combined_score":0.3325511939492621,"distance":4.0337738327377055,"distance_score":0.17765471232432553,"overall_score":0.14651023878985242,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.25310585514464745,"value_score":0.2987579670866074}},"metrics":{"distance":1.7057965129438886,"distance_score":0.3695769416570083,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186637020546823,"value_score":0.6307809903148338},"parent_id":"ff2a1869-014d-4edc-9748-843d38f941eb","timestamp":1747684656.84282},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1200, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing, random search, evolutionary population, and local search.\n    Enhanced exploration, exploitation, and escape from local minima.\n    \"\"\"\n    n_starts = 35  # Further increase restarts for broader coverage\n    pop_size = 12  # Increase population size for more diversity\n    elite_fraction = 0.25  # Keep top individuals\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize a small population for each restart\n        population = []\n        for _ in range(pop_size):\n            ind_x = np.random.uniform(bounds[0], bounds[1])\n            ind_y = np.random.uniform(bounds[0], bounds[1])\n            ind_value = evaluate_function(ind_x, ind_y)\n            population.append([ind_x, ind_y, ind_value])\n\n        temperature = 2.0\n        cooling_rate = 0.995  # Even slower cooling for extended exploration\n        min_temperature = 1e-10  # Allow even finer convergence\n\n        patience = 110\n        no_improve_count = 0\n        local_best_value = min(population, key=lambda ind: ind[2])[2]\n\n        for it in range(iterations // n_starts):\n            # Occasionally do a global random jump for some individuals\n            if it % 32 == 0 and np.random.rand() < 0.45:\n                idx = np.random.randint(pop_size)\n                rand_x = np.random.uniform(bounds[0], bounds[1])\n                rand_y = np.random.uniform(bounds[0], bounds[1])\n                rand_value = evaluate_function(rand_x, rand_y)\n                # Accept jump if better or with probability based on temperature\n                if rand_value < population[idx][2] or np.exp((population[idx][2] - rand_value) / (temperature+1e-12)) > np.random.rand():\n                    population[idx] = [rand_x, rand_y, rand_value]\n                    if rand_value < best_value:\n                        best_x, best_y, best_value = rand_x, rand_y, rand_value\n                    no_improve_count = 0\n\n            # Evolutionary/mutation step for population diversity\n            new_population = []\n            for ind in population:\n                # Candidate generation: Gaussian perturbation\n                perturbation_scale = max(0.45 * temperature, 0.01)\n                mutation_chance = np.clip(0.7 * (1 - temperature), 0.3, 0.9)\n                if np.random.rand() < mutation_chance:\n                    new_x = ind[0] + np.random.normal(0, perturbation_scale)\n                    new_y = ind[1] + np.random.normal(0, perturbation_scale)\n                else:\n                    # Crossover/combination with another random individual\n                    mate = population[np.random.randint(pop_size)]\n                    alpha = np.random.uniform(-0.2, 1.2)\n                    new_x = alpha * ind[0] + (1 - alpha) * mate[0]\n                    new_y = alpha * ind[1] + (1 - alpha) * mate[1]\n                    new_x += np.random.normal(0, perturbation_scale/2)\n                    new_y += np.random.normal(0, perturbation_scale/2)\n                new_x = np.clip(new_x, bounds[0], bounds[1])\n                new_y = np.clip(new_y, bounds[0], bounds[1])\n                new_value = evaluate_function(new_x, new_y)\n                # Simulated annealing acceptance\n                if new_value < ind[2]:\n                    accept = True\n                else:\n                    accept = np.exp((ind[2] - new_value) / (temperature+1e-12)) > np.random.rand()\n                if accept:\n                    new_population.append([new_x, new_y, new_value])\n                else:\n                    new_population.append(ind)\n\n            # Local search: gradient step on the current best in the population\n            if it % 9 == 0:\n                elite = sorted(new_population, key=lambda ind: ind[2])[:max(1,int(elite_fraction*pop_size))]\n                for e in elite:\n                    grad_eps = 1e-5\n                    grad_x = (evaluate_function(e[0] + grad_eps, e[1]) - e[2]) / grad_eps\n                    grad_y = (evaluate_function(e[0], e[1] + grad_eps) - e[2]) / grad_eps\n                    grad_norm = np.sqrt(grad_x**2 + grad_y**2) + 1e-8\n                    step = min(0.15, (0.8 * temperature + 0.05) / grad_norm)  # Adaptive step based on temperature\n                    trial_x = np.clip(e[0] - step * grad_x, bounds[0], bounds[1])\n                    trial_y = np.clip(e[1] - step * grad_y, bounds[0], bounds[1])\n                    trial_value = evaluate_function(trial_x, trial_y)\n                    if trial_value < e[2]:\n                        e[0], e[1], e[2] = trial_x, trial_y, trial_value\n\n            # Survivor selection: keep best, encourage diversity\n            population = sorted(new_population, key=lambda ind: ind[2])\n            # Replace worst with randoms to keep exploration\n            for i in range(int(pop_size*0.18)):\n                rand_x = np.random.uniform(bounds[0], bounds[1])\n                rand_y = np.random.uniform(bounds[0], bounds[1])\n                rand_value = evaluate_function(rand_x, rand_y)\n                population[-(i+1)] = [rand_x, rand_y, rand_value]\n            # Best solution in this generation\n            gen_best = population[0]\n            if gen_best[2] < best_value:\n                best_x, best_y, best_value = gen_best[0], gen_best[1], gen_best[2]\n                no_improve_count = 0\n            elif gen_best[2] < local_best_value:\n                local_best_value = gen_best[2]\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # If stuck, re-initialize part of the population (adaptive restart)\n            if no_improve_count > patience:\n                for i in range(int(pop_size//2)):\n                    population[i][0] = np.random.uniform(bounds[0], bounds[1])\n                    population[i][1] = np.random.uniform(bounds[0], bounds[1])\n                    population[i][2] = evaluate_function(population[i][0], population[i][1])\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":8,"id":"f3a276a9-ca5b-4aed-8ec2-0058e0d81205","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'cooling_rate = 0.991  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.995  # Even slower cooling for extended exploration'\nChange 3: 'step = min(0.12, 0.7 * temperature/2) / grad_norm  # Slightly larger adaptive step' to 'step = min(0.15, (0.8 * temperature + 0.05) / grad_norm)  # Adaptive step based on temperature'\nChange 4: Replace if np.random.rand() < 0.7: with 2 lines","parent_metrics":{"distance":1.7014649692958308,"distance_score":0.37016952333853953,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5185893457006194,"value_score":0.6307514064499059}},"metrics":{"distance":1.711380197339324,"distance_score":0.3688158528934082,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5184171298664773,"value_score":0.6306828982806741},"parent_id":"97cdc700-2675-4141-87a5-dcf93f95bba0","timestamp":1747683874.9865184},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing and local search.\n    Improves exploration and escape from local minima.\n    \"\"\"\n    n_starts = 10  # Increase number of random restarts\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.995  # Slightly slower cooling for more exploration\n        min_temperature = 1e-6  # Lower minimum temperature for finer convergence\n\n        patience = max(60, int(80 * (1 - temperature)))  # Dynamic patience based on temperature\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.4 * temperature, 0.02) * (1 + np.random.uniform(-0.1, 0.1))  # Randomize perturbation scale\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: occasionally make a \"greedy\" step\n            if it % 20 == 0:  # More frequent local search\n                grad_x = (evaluate_function(current_x + 1e-4, current_y) - current_value) / 1e-4\n                grad_y = (evaluate_function(current_x, current_y + 1e-4) - current_value) / 1e-4\n                step = 0.05\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience or temperature < 0.05:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"2564795d-fa97-48bc-9235-9beda242ee38","island":2,"language":"python","metadata":{"changes":"Change 1: 'cooling_rate = 0.995  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.995 + np.random.uniform(0, 0.005)  # Introduce slight randomness for better exploration'\nChange 2: 'perturbation_scale = max(0.4 * temperature, 0.02)  # Larger scale for more jumps at high T' to 'perturbation_scale = max(0.4 * temperature, 0.02) * (1 + np.random.uniform(-0.1, 0.1))  # Randomize perturbation scale'\nChange 3: 'patience = 80' to 'patience = max(60, int(80 * (1 - temperature)))  # Dynamic patience based on temperature'\nChange 4: 'if no_improve_count > patience:' to 'if no_improve_count > patience or temperature < 0.05:'","parent_metrics":{"distance":1.7593274006760315,"distance_score":0.36240715753955155,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5131907328984027,"value_score":0.6286108716364014}},"metrics":{"distance":1.7586767044220888,"distance_score":0.36249263945899324,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5137266826113325,"value_score":0.6288227244119678},"parent_id":"1ebc6456-165b-4e7b-996d-f9ee2fd87198","timestamp":1747683987.0512717},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        if _ > 0 and _ % 100 == 0 and best_value >= current_value:\n            if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\n# Parallel exploration with multiple independent searches\ndef run_search(num_processes=5):\n    results = [search_algorithm() for _ in range(num_processes)]\n    # Return the best result found across all processes\n    return min(results, key=lambda res: res[2])\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"b25f9697-371b-440f-b54c-c7b33fee9955","island":2,"language":"python","metadata":{"changes":"Change 1: Replace perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01) with 2 lines\nChange 2: Replace 5 lines with 7 lines\nChange 3: Replace 3 lines with 5 lines","parent_metrics":{"combined_score":0.33160088894832396,"distance":4.643351228821235,"distance_score":0.1684000789977336,"overall_score":0.14632017778966483,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9004838666565715,"value_score":0.30180144208167314}},"metrics":{"combined_score":0.4748157631584189,"distance":5.142933864815337,"distance_score":0.24393290238043105,"overall_score":0.4949631526316838,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9459474254643492,"value_score":0.5027264874071494},"parent_id":"815b0c81-0ee6-46d2-ac1f-4197fb7c6c29","timestamp":1747683599.184917},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.98  # Faster cooling to escape local minima early\n    min_temperature = 1e-4  # Lower minimum temperature for finer convergence\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = max(0.5 * temperature * np.exp(-0.03 * _), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a dynamic restart mechanism based on stagnation\n        stagnation_threshold = 150\n        if _ > stagnation_threshold and best_value >= current_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n            stagnation_threshold += 50  # Increase threshold to allow more iterations before next restart\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"a33b54f3-92e1-4539-8a59-a3b0ac75642f","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)' to 'perturbation_scale = max(0.5 * temperature * np.exp(-0.03 * _), 0.01)'\nChange 3: Replace 7 lines with 7 lines","parent_metrics":{"combined_score":0.3349001626270999,"distance":0.4841698181420444,"distance_score":0.1679899341660393,"overall_score":0.14698003252542,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.1066303074044817,"value_score":0.30750530396214687}},"metrics":{"distance":1.6056142455118263,"distance_score":0.38378666440072673,"overall_score":0.5,"runs_successfully":1.0,"value":-1.252750305671682,"value_score":0.5401756462478856},"parent_id":"98b9ce65-f2d7-4049-a6c4-6dd4c6a6ea01","timestamp":1747683960.2170763},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start simulated annealing and basin hopping.\n    Focuses on exploration and robust escape from local minima.\n    \"\"\"\n    def random_point():\n        return np.random.uniform(bounds[0], bounds[1]), np.random.uniform(bounds[0], bounds[1])\n\n    def clipped(x):\n        return np.clip(x, bounds[0], bounds[1])\n\n    def local_minimize(x0, y0, steps=40, initial_lr=0.02):\n        # Adaptive learning rate\n        lr = initial_lr\n        # Simple gradient descent for local refinement\n        x, y = x0, y0\n        for _ in range(steps):\n            grad_x = np.cos(x) * np.cos(y) + y * np.cos(x * y) + x/10\n            grad_y = -np.sin(x) * np.sin(y) + x * np.cos(x * y) + y/10\n            x = clipped(x - lr * grad_x)\n            y = clipped(y - lr * grad_y)\n            lr *= 0.95  # Decrease learning rate to improve convergence\n        return x, y, evaluate_function(x, y)\n\n    n_starts = 12  # Increase the number of starts for better exploration\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Simulated annealing per start\n        current_x, current_y = random_point()\n        current_value = evaluate_function(current_x, current_y)\n        temperature = 2.0\n        cooling_rate = 0.98 if temperature > 1 else 0.995  # Dynamic cooling rate\n        min_temperature = 1e-4\n        for it in range(iterations // n_starts):\n            perturbation_scale = max(0.25 * temperature, 0.05)\n            new_x = clipped(current_x + np.random.uniform(-perturbation_scale, perturbation_scale))\n            new_y = clipped(current_y + np.random.uniform(-perturbation_scale, perturbation_scale))\n            new_value = evaluate_function(new_x, new_y)\n            if new_value < current_value or np.exp((current_value - new_value) / temperature) > np.random.rand():\n                current_x, current_y, current_value = new_x, new_y, new_value\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Basin hopping: after annealing, perform local descent\n        local_x, local_y, local_val = local_minimize(current_x, current_y)\n        if local_val < best_value:\n            best_x, best_y, best_value = local_x, local_y, local_val\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"c6fea3a7-8022-4565-9641-2f9496ccbd12","island":2,"language":"python","metadata":{"changes":"Change 1: Replace def local_minimize(x0, y0, steps=40, lr=0.02): with 3 lines\nChange 2: Replace 2 lines with 3 lines\nChange 3: 'n_starts = 8' to 'n_starts = 12  # Increase the number of starts for better exploration'\nChange 4: 'cooling_rate = 0.96' to 'cooling_rate = 0.98 if temperature > 1 else 0.995  # Dynamic cooling rate'","parent_metrics":{"distance":1.7085977494900697,"distance_score":0.3691947245353296,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186743726058185,"value_score":0.6307852359919973}},"metrics":{"distance":1.4336776251968648,"distance_score":0.4109007658395627,"overall_score":0.5,"runs_successfully":1.0,"value":-1.1112634396505654,"value_score":0.5018224786444656},"parent_id":"6faffe31-1302-4428-b4dc-abfa216f23b3","timestamp":1747683748.9718711},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        if _ % 100 == 0 and current_value >= best_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":4,"id":"f533ce2b-cb5a-43ff-9fb0-2b7eafb531bd","island":2,"language":"python","metadata":{"changes":"Change 1: Replace cooling_rate = 0.995  # Slightly slower cooling for more exploration with 2 lines\nChange 2: Replace perturbation_scale = max(0.1 * temperature, 0.01)  # Scale perturbation with temperature with 2 lines\nChange 3: Replace if _ % 100 == 0 and current_value >= best_value: with 6 lines","parent_metrics":{"combined_score":0.433522602887764,"distance":2.2667820605960056,"distance_score":0.24475679833575634,"overall_score":0.4867045205775528,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1516535921724969,"value_score":0.43349260564506187}},"metrics":{"combined_score":0.4258850392234609,"distance":3.5144723081215075,"distance_score":0.23192590491212237,"overall_score":0.4851770078446922,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.6030190517040648,"value_score":0.42717877958304035},"parent_id":"57f20e0e-88a3-4ba4-898f-ee581aac3168","timestamp":1747683889.0358222},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5), restarts=5, swarm_size=10):\n    \"\"\"\n    Hybrid Simulated Annealing with Random Restarts and Particle Swarm-inspired multi-starts.\n    The algorithm attempts to reliably find the global minimum by running multiple independent \n    simulated annealing processes (swarm) and restarting the best if progress stalls.\n\n    Args:\n        iterations: Number of iterations per swarm member\n        bounds: Bounds for the search space (min, max)\n        restarts: Number of random restarts for the best candidate\n        swarm_size: Number of independent search agents\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    def anneal_once(init_x, init_y, iterations, bounds):\n        current_x, current_y = init_x, init_y\n        current_value = evaluate_function(current_x, current_y)\n        best_x, best_y, best_value = current_x, current_y, current_value\n        temperature = 1.0\n        cooling_rate = 0.995\n        min_temperature = 1e-3\n        no_improve_count = 0\n        for i in range(iterations):\n            perturbation_scale = max(0.2 * temperature, 0.05) # More exploration\n            new_x = np.clip(current_x + np.random.uniform(-perturbation_scale, perturbation_scale), bounds[0], bounds[1])\n            new_y = np.clip(current_y + np.random.uniform(-perturbation_scale, perturbation_scale), bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n            # If stuck for a while, jump to a new region\n            if no_improve_count > 150:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n            temperature = max(temperature * cooling_rate, min_temperature)\n        return best_x, best_y, best_value\n\n    # Swarm initialization: multiple independent searches\n    swarm = []\n    for _ in range(swarm_size):\n        start_x = np.random.uniform(bounds[0], bounds[1])\n        start_y = np.random.uniform(bounds[0], bounds[1])\n        bx, by, bv = anneal_once(start_x, start_y, iterations, bounds)\n        swarm.append((bx, by, bv))\n    # Find the best from the swarm\n    best_x, best_y, best_value = min(swarm, key=lambda t: t[2])\n\n    # Perform random restarts from the best found so far\n    for _ in range(restarts):\n        rx = np.random.uniform(bounds[0], bounds[1])\n        ry = np.random.uniform(bounds[0], bounds[1])\n        # Try both a global random restart and a local perturbation from current best\n        bx1, by1, bv1 = anneal_once(rx, ry, iterations, bounds)\n        bx2, by2, bv2 = anneal_once(\n            np.clip(best_x + np.random.normal(0, 1), bounds[0], bounds[1]),\n            np.clip(best_y + np.random.normal(0, 1), bounds[0], bounds[1]),\n            iterations, bounds)\n        candidates = [(best_x, best_y, best_value), (bx1, by1, bv1), (bx2, by2, bv2)]\n        best_x, best_y, best_value = min(candidates, key=lambda t: t[2])\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"88698633-0f8c-4ad9-b03d-b801167e9efc","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 52 lines with 72 lines","parent_metrics":{"combined_score":0.42971142162308373,"distance":2.1481463061683357,"distance_score":0.2388252066022703,"overall_score":0.4859422843246168,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4470917790682061,"value_score":0.4301064327373378}},"metrics":{"distance":1.7066254910560772,"distance_score":0.36946374860668946,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186785500296518,"value_score":0.6307868981516045},"parent_id":"39d3c5b7-a779-4a2c-888b-13bc4ffc8966","timestamp":1747683944.4701865},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x, best_y, best_value = None, None, float('inf')\n    n_starts = 20  # Increase number of random restarts to enhance exploration\n\n    for _ in range(n_starts):\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 1.0\n        cooling_rate = 0.99  # Slightly more aggressive cooling for better convergence\n\n        for i in range(iterations):\n            # Adaptive perturbation size based on temperature\n            perturbation_size = max(0.05, temperature / (1 + best_value))  # Dynamic adjustment based on best value\n            new_x = current_x + np.random.uniform(-perturbation_size, perturbation_size)\n            new_y = current_y + np.random.uniform(-perturbation_size, perturbation_size)\n            new_value = evaluate_function(new_x, new_y)\n\n            # Calculate acceptance probability\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            # Accept the new solution\n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            # Update the best solution found\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n\n            # Dynamic cooling schedule\n            temperature *= cooling_rate * (1 - (i / iterations))\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":3,"id":"9d127568-0ddb-4203-abc5-403471b6f568","island":2,"language":"python","metadata":{"changes":"Change 1: 'n_starts = 5  # Number of random restarts' to 'n_starts = 20  # Increase number of random restarts to enhance exploration'\nChange 2: 'cooling_rate = 0.995' to 'cooling_rate = 0.99  # Slightly more aggressive cooling for better convergence'\nChange 3: 'perturbation_size = max(0.1, temperature / 2.0)' to 'perturbation_size = max(0.05, temperature / (1 + best_value))  # Dynamic adjustment based on best value'","parent_metrics":{"combined_score":0.5224576607937255,"distance":5.192335910281548,"distance_score":0.22030065048037717,"overall_score":0.18449153215874511,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.4204747531363051,"value_score":0.5939457760826873}},"metrics":{"distance":1.708861485041154,"distance_score":0.36915877962833804,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186853671718463,"value_score":0.6307896106503667},"parent_id":"706d13f2-4663-46f6-93b6-78fcf043b2db","timestamp":1747683469.1582835},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Improved global optimization using multi-start simulated annealing and basin hopping.\n    Focuses on exploration and robust escape from local minima.\n    \"\"\"\n    def random_point():\n        return np.random.uniform(bounds[0], bounds[1]), np.random.uniform(bounds[0], bounds[1])\n\n    def clipped(x):\n        return np.clip(x, bounds[0], bounds[1])\n\n    def local_minimize(x0, y0, steps=40, lr=0.02):\n        # Simple gradient descent for local refinement\n        x, y = x0, y0\n        for _ in range(steps):\n            grad_x = np.cos(x) * np.cos(y) + y * np.cos(x * y) + x/10\n            grad_y = -np.sin(x) * np.sin(y) + x * np.cos(x * y) + y/10\n            x = clipped(x - lr * grad_x)\n            y = clipped(y - lr * grad_y)\n        return x, y, evaluate_function(x, y)\n\n    n_starts = 8\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Simulated annealing per start\n        current_x, current_y = random_point()\n        current_value = evaluate_function(current_x, current_y)\n        temperature = 2.0\n        cooling_rate = 0.96\n        min_temperature = 1e-4\n        for it in range(iterations // n_starts):\n            perturbation_scale = max(0.25 * temperature, 0.05)\n            new_x = clipped(current_x + np.random.uniform(-perturbation_scale, perturbation_scale))\n            new_y = clipped(current_y + np.random.uniform(-perturbation_scale, perturbation_scale))\n            new_value = evaluate_function(new_x, new_y)\n            if new_value < current_value or np.exp((current_value - new_value) / temperature) > np.random.rand():\n                current_x, current_y, current_value = new_x, new_y, new_value\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Basin hopping: after annealing, perform local descent\n        local_x, local_y, local_val = local_minimize(current_x, current_y)\n        if local_val < best_value:\n            best_x, best_y, best_value = local_x, local_y, local_val\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"6faffe31-1302-4428-b4dc-abfa216f23b3","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 71 lines with 48 lines","parent_metrics":{"error":0.0}},"metrics":{"distance":1.7085977494900697,"distance_score":0.3691947245353296,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186743726058185,"value_score":0.6307852359919973},"parent_id":"4f47720f-4f9d-43e1-b1f1-1eda6708c5e3","timestamp":1747683685.8419945},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Random restart function to initialize a new search point\n    def random_restart():\n        return (np.random.uniform(bounds[0], bounds[1]), \n                np.random.uniform(bounds[0], bounds[1]), \n                float('inf'))  # Start with a high value to ensure any real evaluation is better\n\n    # Initialize with a random point\n    current_x, current_y, current_value = random_restart()\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.99  # Adjust cooling rate for better exploration\n    min_temperature = 1e-3\n    no_improvement_threshold = 200  # Number of iterations to trigger a restart\n    last_improvement_iteration = 0  # Track the last improvement\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        perturbation_scale = max(0.1 * temperature, 0.05)  # Adjusted to allow broader exploration\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Check for improvement\n        if current_value < best_value:\n            last_improvement_iteration = _  # Update last improvement\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Restart if no improvement\n        if _ - last_improvement_iteration > no_improvement_threshold:\n            current_x, current_y, current_value = random_restart()\n            last_improvement_iteration = _  # Reset improvement tracker\n\n        # Perform a local search step after a restart\n        if _ % no_improvement_threshold == 0:\n            gradient_step = 0.01  # Small step for local search\n            grad_x = np.cos(current_x) * np.cos(current_y) + current_y * np.cos(current_x * current_y) + current_x / 10\n            grad_y = -np.sin(current_x) * np.sin(current_y) + current_x * np.cos(current_x * current_y) + current_y / 10\n            current_x -= gradient_step * grad_x\n            current_y -= gradient_step * grad_y\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"cbace538-30c1-4370-8ee7-46e2dd00371c","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature, 0.05)  # Adjusted to allow broader exploration' to 'perturbation_scale = max(0.2 * temperature, 0.01)  # Increased initial scale for broader exploration'\nChange 3: Replace 2 lines with 2 lines","parent_metrics":{"error":0.0}},"metrics":{"combined_score":0.5020846298652628,"distance":2.8298516401660767,"distance_score":0.2559468909629838,"overall_score":0.5004169259730527,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.1505276454007851,"value_score":0.5421676042939461},"parent_id":"4f47720f-4f9d-43e1-b1f1-1eda6708c5e3","timestamp":1747683527.8151245},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid global optimization using multistart simulated annealing, random search, and local search.\n    Enhanced exploration, exploitation, and escape from local minima.\n    \"\"\"\n    n_starts = 20  # Increase number of random restarts for more global coverage\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point for each restart\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        \n        temperature = 2.0\n        cooling_rate = 0.992  # Even slower cooling for more exploration\n        min_temperature = 1e-8  # Allow more fine convergence\n\n        patience = 120\n        no_improve_count = 0\n\n        for it in range(iterations // n_starts):\n            # Occasionally do a global random jump to escape local minima\n            if it % 35 == 0 and np.random.rand() < 0.40:\n                rand_x = np.random.uniform(bounds[0], bounds[1])\n                rand_y = np.random.uniform(bounds[0], bounds[1])\n                rand_value = evaluate_function(rand_x, rand_y)\n                if rand_value < current_value or np.exp((current_value - rand_value) / (temperature+1e-12)) > np.random.rand():\n                    current_x, current_y, current_value = rand_x, rand_y, rand_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # Generate a new candidate point by adding a perturbation\n            perturbation_scale = max(0.7 * temperature, 0.01)  # Larger scale for more jumps at high T\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n\n            # Enforce bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n\n            new_value = evaluate_function(new_x, new_y)\n\n            # Acceptance criteria (Simulated Annealing)\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / (temperature+1e-12)) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            # Update best found so far\n            if current_value < best_value:\n                best_x, best_y, best_value = current_x, current_y, current_value\n                no_improve_count = 0\n\n            # Local search: hybridize with adaptive step gradient descent\n            if it % 12 == 0:  # More frequent local search\n                grad_eps = 1e-5\n                grad_x = (evaluate_function(current_x + grad_eps, current_y) - current_value) / grad_eps\n                grad_y = (evaluate_function(current_x, current_y + grad_eps) - current_value) / grad_eps\n                grad_norm = np.sqrt(grad_x**2 + grad_y**2) + 1e-8\n                step = min(0.08, 0.5 * temperature/2) / grad_norm  # Adaptive step size\n                trial_x = np.clip(current_x - step * grad_x, bounds[0], bounds[1])\n                trial_y = np.clip(current_y - step * grad_y, bounds[0], bounds[1])\n                trial_value = evaluate_function(trial_x, trial_y)\n                if trial_value < current_value:\n                    current_x, current_y, current_value = trial_x, trial_y, trial_value\n                    if current_value < best_value:\n                        best_x, best_y, best_value = current_x, current_y, current_value\n                    no_improve_count = 0\n\n            # If stuck, jump to a new random position (adaptive restart)\n            if no_improve_count > patience:\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"350e2a5b-a4bb-49eb-91ba-d8428603711d","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 74 lines with 87 lines","parent_metrics":{"distance":1.6149312762401669,"distance_score":0.3824192280256911,"overall_score":0.5,"runs_successfully":1.0,"value":-1.4981511396923075,"value_score":0.6227236103704009}},"metrics":{"distance":1.7365245964003113,"distance_score":0.36542700961483165,"overall_score":0.5,"runs_successfully":1.0,"value":-1.4989040660672401,"value_score":0.6230157206552936},"parent_id":"fbc34e4f-c22a-4e83-9d2b-3cbaa8ad7608","timestamp":1747683574.8825357},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        if _ > 0 and _ % 100 == 0 and best_value >= current_value:\n            if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"3e83b0cb-948b-47dd-918e-16079b60cd73","island":2,"language":"python","metadata":{"changes":"Change 1: Replace perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01) with 2 lines\nChange 2: Replace 5 lines with 6 lines\nChange 3: 'cooling_rate = 0.995  # Slightly slower cooling for more exploration' to 'cooling_rate = 0.998  # Even slower cooling for better exploration in complex landscapes'","parent_metrics":{"combined_score":0.33160088894832396,"distance":4.643351228821235,"distance_score":0.1684000789977336,"overall_score":0.14632017778966483,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9004838666565715,"value_score":0.30180144208167314}},"metrics":{"combined_score":0.3896725976796959,"distance":3.0478958065761943,"distance_score":0.20564415911374603,"overall_score":0.47793451953593924,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-1.0999303497626434,"value_score":0.37996558324262025},"parent_id":"815b0c81-0ee6-46d2-ac1f-4197fb7c6c29","timestamp":1747684524.691925},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.99\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        new_x = current_x + np.random.uniform(-0.1, 0.1)\n        new_y = current_y + np.random.uniform(-0.1, 0.1)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        temperature *= cooling_rate\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":1,"id":"587b41ec-9e19-43ef-9756-ff4ecdfa1afd","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 27 lines with 44 lines","parent_metrics":{"distance":1.7121946646425519,"distance_score":0.3687050981393303,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5124300045855732,"value_score":0.628310412285456}},"metrics":{"combined_score":0.4340846850557817,"distance":6.116510764280398,"distance_score":0.23743554909359196,"overall_score":0.48681693701115636,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6790898014054345,"value_score":0.4380900338795069},"parent_id":"671651af-3148-47b4-ba64-5f6df7a748f7","timestamp":1747683308.3015606},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A robust global optimization algorithm combining multi-start, simulated annealing, random restarts,\n    and a final local search to refine the found minimum.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Multi-start: run several independent simulated annealing searches\n    n_starts = 18  # Slightly increased for better coverage\n    best_x, best_y, best_value = None, None, np.inf\n\n    for start in range(n_starts):\n        # Initialize with a random point\n        current_x = np.random.uniform(bounds[0], bounds[1])\n        current_y = np.random.uniform(bounds[0], bounds[1])\n        current_value = evaluate_function(current_x, current_y)\n        local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n\n        temperature = 3.0  # Higher starting temperature for more exploration\n        min_temperature = 1e-4\n\n        no_improve_count = 0\n        last_improve_iter = 0\n        max_no_improve = iterations // 10  # More frequent restarts\n\n        for i in range(iterations // n_starts):\n            # Dynamic cooling rate: slower at start, faster if stuck\n            if no_improve_count > (iterations // (4 * n_starts)):\n                cooling_rate = 0.96\n            elif i < (iterations // (5 * n_starts)):\n                cooling_rate = 0.997\n            else:\n                cooling_rate = 0.991\n\n            # Generate a new candidate point by adding a scaled perturbation\n            perturbation_scale = max(0.7 * temperature, 0.1 * (1 - (i / iterations)))\n            new_x = current_x + np.random.normal(0, perturbation_scale)\n            new_y = current_y + np.random.normal(0, perturbation_scale)\n            # Ensure inside bounds\n            new_x = np.clip(new_x, bounds[0], bounds[1])\n            new_y = np.clip(new_y, bounds[0], bounds[1])\n            new_value = evaluate_function(new_x, new_y)\n\n            if new_value < current_value:\n                accept = True\n            else:\n                accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n            \n            if accept:\n                current_x, current_y, current_value = new_x, new_y, new_value\n\n            if current_value < local_best_value:\n                local_best_x, local_best_y, local_best_value = current_x, current_y, current_value\n                no_improve_count = 0\n                last_improve_iter = i\n            else:\n                no_improve_count += 1\n\n            # Random restart if no improvement for several iterations\n            if no_improve_count > max_no_improve or (i - last_improve_iter) > iterations // (2 * n_starts):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n                no_improve_count = 0\n\n            temperature = max(temperature * cooling_rate, min_temperature)\n\n        # Local search refinement: simple coordinate descent near local best\n        refine_steps = 10\n        step_size = 0.15\n        rx, ry = local_best_x, local_best_y\n        rv = local_best_value\n        for j in range(refine_steps):\n            improved = False\n            for dx, dy in [(-step_size,0),(step_size,0),(0,-step_size),(0,step_size)]:\n                tx = np.clip(rx+dx, bounds[0], bounds[1])\n                ty = np.clip(ry+dy, bounds[0], bounds[1])\n                tv = evaluate_function(tx, ty)\n                if tv < rv:\n                    rx, ry, rv = tx, ty, tv\n                    improved = True\n            if not improved:\n                step_size *= 0.5  # shrink neighborhood\n\n        # Update best found across all starts\n        if rv < best_value:\n            best_x, best_y, best_value = rx, ry, rv\n\n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"4641484f-d863-43fb-93da-772e4dd52df3","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 77 lines with 94 lines","parent_metrics":{"error":0.0}},"metrics":{"distance":1.7085908191466181,"distance_score":0.3691956691764409,"overall_score":0.5,"runs_successfully":1.0,"value":-1.5186854006015231,"value_score":0.630789623951886},"parent_id":"efccd91b-297f-4029-b9f9-effe9a3f538e","timestamp":1747684083.309442},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.995  # Slightly slower cooling for more exploration\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)\n        new_x = current_x + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_y = current_y + np.random.uniform(-perturbation_scale, perturbation_scale)\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        if _ > 0 and _ % 100 == 0 and best_value >= current_value:\n            if all(evaluate_function(current_x + dx, current_y + dy) >= current_value for dx, dy in [(-0.1, 0), (0.1, 0), (0, -0.1), (0, 0.1)]):\n                current_x = np.random.uniform(bounds[0], bounds[1])\n                current_y = np.random.uniform(bounds[0], bounds[1])\n                current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\n# Parallel exploration with multiple independent searches\ndef run_search(num_processes=5):\n    results = [search_algorithm() for _ in range(num_processes)]\n    # Return the best result found across all processes\n    return min(results, key=lambda res: res[2])\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":6,"id":"e41f27e4-bebf-4000-bac4-a43d8a99f66b","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 3 lines with 3 lines\nChange 2: 'perturbation_scale = max(0.1 * temperature * (1 if _ % 50 == 0 else 0.5), 0.01)' to 'perturbation_scale = max(0.2 * temperature * (1 if _ % 50 == 0 else 0.3), 0.01)'\nChange 3: Replace 5 lines with 7 lines","parent_metrics":{"combined_score":0.4748157631584189,"distance":5.142933864815337,"distance_score":0.24393290238043105,"overall_score":0.4949631526316838,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.9459474254643492,"value_score":0.5027264874071494}},"metrics":{"combined_score":0.41448005132796584,"distance":5.303652308932938,"distance_score":0.20781182077833207,"overall_score":0.4828960102655932,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.4977901712249587,"value_score":0.42022750849077706},"parent_id":"b25f9697-371b-440f-b54c-c7b33fee9955","timestamp":1747684830.1480515},{"code":"# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    An improved search algorithm using simulated annealing to escape local minima.\n    \n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n        \n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    current_x = np.random.uniform(bounds[0], bounds[1])\n    current_y = np.random.uniform(bounds[0], bounds[1])\n    current_value = evaluate_function(current_x, current_y)\n    \n    best_x, best_y, best_value = current_x, current_y, current_value\n    temperature = 1.0\n    cooling_rate = 0.98  # Faster cooling to allow better convergence\n    min_temperature = 1e-3  # Introduce a minimum temperature to prevent early stopping\n\n    for _ in range(iterations):\n        # Generate a new candidate point by adding a small perturbation\n        # Adaptive perturbation based on recent improvements\n        perturbation_scale = 0.1 * temperature\n        new_x = current_x + np.random.normal(0, perturbation_scale)\n        new_y = current_y + np.random.normal(0, perturbation_scale)\n        \n        # Ensure new_x and new_y remain within bounds\n        new_x = np.clip(new_x, bounds[0], bounds[1])\n        new_y = np.clip(new_y, bounds[0], bounds[1])\n        new_value = evaluate_function(new_x, new_y)\n\n        # Calculate acceptance probability\n        if new_value < current_value:\n            accept = True\n        else:\n            accept = np.exp((current_value - new_value) / temperature) > np.random.rand()\n        \n        # Accept the new solution\n        if accept:\n            current_x, current_y, current_value = new_x, new_y, new_value\n\n        # Update the best solution found\n        if current_value < best_value:\n            best_x, best_y, best_value = current_x, current_y, current_value\n\n        # Cool down the temperature\n        # Implement a restart mechanism if no improvement is found in a certain number of iterations\n        # Intelligent restart mechanism\n        # Trigger restart if no improvement in last 200 iterations\n        if _ > 0 and _ % 200 == 0 and best_value >= current_value:\n            current_x = np.random.uniform(bounds[0], bounds[1])\n            current_y = np.random.uniform(bounds[0], bounds[1])\n            current_value = evaluate_function(current_x, current_y)\n        \n        temperature = max(temperature * cooling_rate, min_temperature)\n    \n    return best_x, best_y, best_value\n\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x*y) + (x**2 + y**2)/20\n# EVOLVE-BLOCK-END\n\n# This part remains fixed (not evolved)\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n    # The global minimum is around (-1.76, -1.03) with value -2.104\n","complexity":0.0,"diversity":0.0,"generation":5,"id":"d5a8d81c-17fb-4052-97c3-34ed292ddbb1","island":2,"language":"python","metadata":{"changes":"Change 1: Replace 2 lines with 2 lines\nChange 2: Replace 4 lines with 15 lines","parent_metrics":{"combined_score":0.35371181446008193,"distance":5.481650992896429,"distance_score":0.1794633008683563,"overall_score":0.15074236289201642,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":-0.8806981423956454,"value_score":0.33312137366595845}},"metrics":{"combined_score":0.3734818844387957,"distance":6.03703455848181,"distance_score":0.2282103926525655,"overall_score":0.15469637688775917,"reliability_score":1.0,"runs_successfully":1.0,"speed_score":1.0,"success_rate":1.0,"value":0.6053483184137962,"value_score":0.3416979444050435},"parent_id":"dfb9bd3c-165a-4db2-aebc-b1f319a43e81","timestamp":1747684262.6575747}]}
;</script>
<script type="module" src="static/js/state.js"></script>
    <script type="module" src="static/js/main.js"></script>
    <script type="module" src="static/js/mainUI.js"></script>
    <script type="module" src="static/js/sidebar.js"></script>
    <script type="module" src="static/js/graph.js"></script>
    <script type="module" src="static/js/performance.js"></script>
    <script type="module" src="static/js/list.js"></script>
</body>
</html>