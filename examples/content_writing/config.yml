max_iterations: 1
checkpoint_interval: 1
log_level: "INFO"

# LLM configuration
llm:
  models:
    - name: "llama3.1-8b"
      weight: 0.8
      temperature: 1.5
    - name: "llama-4-scout-17b-16e-instruct"
      weight: 0.2
      temperature: 0.9
  evaluator_models:
    - name: "llama-4-scout-17b-16e-instruct"
      weight: 1.0
      temperature: 0.9
  # api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
  # api_base: "https://api.openai.com/v1/"
  # api_base: "http://localhost:11434/v1/"
  api_base: "https://api.cerebras.ai/v1/"
  top_p: 0.95
  max_tokens: 4096

# Prompt configuration
prompt:
  num_top_programs: 3
  use_template_stochasticity: true
  template_dir: "examples/content_writing/prompts"
  num_top_programs: 0                 # Number of top-performing programs to include
  num_diverse_programs: 0             # Number of diverse programs to include

# Database configuration
database:
  num_islands: 10
  elite_selection_ratio: 0.1
  exploitation_ratio: 0.7
  log_prompts: true

# Evaluator configuration
evaluator:
  timeout: 60
  cascade_evaluation: true
  parallel_evaluations: 1
  use_llm_feedback: true
  llm_feedback_weight: 1.0


# Evolution settings
diff_based_evolution: true
allow_full_rewrites: false
